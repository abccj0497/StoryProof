import json
import torch
import os
from sentence_transformers import SentenceTransformer, util

# --- ì„¤ì • ---
# í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¶ì€ íŒŒì¼ëª…ì„ ì—¬ê¸°ì— ì ìœ¼ì„¸ìš” (í•˜ë‚˜ì”© ë°”ê¿”ê°€ë©° í…ŒìŠ¤íŠ¸)
TARGET_FILE = "03_sliding_data.json" 
# TARGET_FILE = "01_entity_data.json"
# TARGET_FILE = "02_recursive_data.json"

QUESTIONS = [
    "1. ì•¨ë¦¬ìŠ¤ê°€ í† ë¼ êµ´ë¡œ ë”°ë¼ë“¤ì–´ê°„ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€?",
    "2. í•˜ì–€ í† ë¼ê°€ ë“¤ê³  ë‹¤ë‹ˆë˜ ë¬¼ê±´ë“¤ì€ ë¬´ì—‡ì¸ê°€?",
    "3. ìê¸°ë²Œë ˆ(ì• ë²Œë ˆ)ëŠ” ì•¨ë¦¬ìŠ¤ì—ê²Œ ì–´ë–¤ ì¡°ì–¸ì„ í–ˆëŠ”ê°€?",
    "4. ì²´ì…” ê³ ì–‘ì´ì˜ ê°€ì¥ í° íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€?",
    "5. ì¬íŒì¥ì—ì„œ ì•¨ë¦¬ìŠ¤ëŠ” ì™•ê³¼ ì—¬ì™•ì—ê²Œ ë­ë¼ê³  ì†Œë¦¬ì³¤ëŠ”ê°€?"
]

def run_test():
    if not os.path.exists(TARGET_FILE):
        print(f"âŒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {TARGET_FILE}")
        return

    print(f">>> [{TARGET_FILE}] ë°ì´í„° ë¡œë”© ë° ê²€ìƒ‰ ì¤€ë¹„...")
    model = SentenceTransformer('Alibaba-NLP/gte-multilingual-base', trust_remote_code=True)
    
    with open(TARGET_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)

    corpus_embeddings = torch.tensor([d['embedding'] for d in data])
    query_embeddings = model.encode(QUESTIONS, convert_to_tensor=True)

    # ê²€ìƒ‰ ì‹¤í–‰
    results = util.semantic_search(query_embeddings, corpus_embeddings, top_k=1)

    print(f"\n======== [{TARGET_FILE}] ì²­í‚¹ ê²°ê³¼ ë° ê²€ìƒ‰ í™•ì¸ ========")
    
    for i, res in enumerate(results):
        best = res[0]
        score = best['score']
        doc = data[best['corpus_id']] # ì°¾ì•„ë‚¸ ë¬¸ì„œ ë©ì–´ë¦¬
        
        print(f"\nâ“ ì§ˆë¬¸ Q{i+1}: {QUESTIONS[i]}")
        print(f"ğŸ’ ìœ ì‚¬ë„ ì ìˆ˜: {score:.4f}")
        print(f"ğŸ“„ [ì²­í‚¹ëœ ì „ì²´ í…ìŠ¤íŠ¸ í™•ì¸] :")
        print("-" * 40)
        print(doc['content']) # <--- ì—¬ê¸°ì„œ ì˜ë¦° í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        print("-" * 40)

if __name__ == "__main__":
    run_test()