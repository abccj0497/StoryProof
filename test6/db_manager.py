import os
import json
import psycopg2
from psycopg2 import extras
from typing import List, Dict, Any
import chromadb
from chromadb.utils import embedding_functions

class DBManager:
    def __init__(self, chroma_path: str = "test6_db/chroma_db"):
        # PostgreSQL ì—°ê²° ì •ë³´ (í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’)
        self.pg_config = {
            "host": os.getenv("DB_HOST", "localhost"),
            "port": os.getenv("DB_PORT", "5432"),
            "database": os.getenv("DB_NAME", "storyproof"),
            "user": os.getenv("DB_USER", "postgres"),
            "password": os.getenv("DB_PASSWORD", "password") # ì‹¤ì œ ì‚¬ìš© ì‹œ í™˜ê²½ ë³€ìˆ˜ ê¶Œìž¥
        }
        
        # ChromaDB ì„¤ì •
        if not os.path.exists(os.path.dirname(chroma_path)):
            os.makedirs(os.path.dirname(chroma_path))
            
        self.chroma_client = chromadb.PersistentClient(path=chroma_path)
        self.embedding_fn = embedding_functions.DefaultEmbeddingFunction()
        self.collection = self.chroma_client.get_or_create_collection(
            name="novel_scenes",
            embedding_function=self.embedding_fn
        )
        
        # PostgreSQL ì´ˆê¸°í™”
        self._init_postgres()

    def _get_pg_connection(self):
        return psycopg2.connect(**self.pg_config)

    def _init_postgres(self):
        conn = self._get_pg_connection()
        cursor = conn.cursor()
        
        # ìž¥ë©´ ì •ë³´ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS scenes (
                scene_id TEXT PRIMARY KEY,
                title TEXT,
                summary TEXT,
                atmosphere TEXT,
                keywords JSONB
            )
        ''')
        
        # ìºë¦­í„°/ìž¥ì†Œ/ì•„ì´í…œ ì„¤ì • í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS entities (
                id SERIAL PRIMARY KEY,
                scene_id TEXT REFERENCES scenes(scene_id),
                name TEXT,
                type TEXT,
                description TEXT,
                action TEXT
            )
        ''')
        
        # ì„¤ì • ì˜¤ë¥˜ ë¡œê·¸ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS consistency_errors (
                id SERIAL PRIMARY KEY,
                scene_id TEXT REFERENCES scenes(scene_id),
                entity_name TEXT,
                error_type TEXT,
                description TEXT,
                severity TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        cursor.close()
        conn.close()

    def save_scene_analysis(self, scene_id: str, text: str, analysis: Dict[str, Any]):
        # 1. ChromaDB ì €ìž¥ (RAGìš©)
        # ì¤‘ìš”: ìš”ì•½(summary) ì •ë³´ë¥¼ ë²¡í„°í™”í•˜ì—¬ ì €ìž¥ì„± í–¥ìƒ
        summary_text = analysis.get("summary", "")
        
        # ì—”í‹°í‹° ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ë©”íƒ€ë°ì´í„°ì— í¬í•¨ (í•„í„°ë§ ìš©ë„)
        entity_names = [e.get("name") for e in analysis.get("entities", [])]
        
        metadata = {
            "scene_id": scene_id,
            "title": analysis.get("scene_title", ""),
            "entities": ",".join(entity_names) if entity_names else ""
        }
        
        self.collection.upsert(
            ids=[scene_id],
            documents=[summary_text], # ì›ë³¸ í…ìŠ¤íŠ¸ ëŒ€ì‹  ìš”ì•½ì„ ë²¡í„°í™”
            metadatas=[metadata]
        )
        
        # 2. PostgreSQL ì €ìž¥ (ìƒì„¸ ë°ì´í„° ë³´ê´€)
        conn = self._get_pg_connection()
        cursor = conn.cursor()
        
        try:
            # ìž¥ë©´ ì •ë³´ (Upsert)
            cursor.execute('''
                INSERT INTO scenes (scene_id, title, summary, atmosphere, keywords)
                VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT (scene_id) DO UPDATE SET
                    title = EXCLUDED.title,
                    summary = EXCLUDED.summary,
                    atmosphere = EXCLUDED.atmosphere,
                    keywords = EXCLUDED.keywords
            ''', (
                scene_id,
                analysis.get("scene_title", ""),
                analysis.get("summary", ""),
                analysis.get("atmosphere", ""),
                json.dumps(analysis.get("keywords", []))
            ))
            
            # ê°œì²´ ì •ë³´
            for ent in analysis.get("entities", []):
                cursor.execute('''
                    INSERT INTO entities (scene_id, name, type, description, action)
                    VALUES (%s, %s, %s, %s, %s)
                ''', (
                    scene_id,
                    ent.get("name"),
                    ent.get("type"),
                    ent.get("desc"),
                    ent.get("action")
                ))
            
            conn.commit()
        except Exception as e:
            conn.rollback()
            print(f"âŒ PostgreSQL ì €ìž¥ ì‹¤íŒ¨: {e}")
        finally:
            cursor.close()
            conn.close()

    def get_context_for_chatbot(self, query: str, filters: Dict = None, n_results: int = 3) -> str:
        # ChromaDBì—ì„œ ê´€ë ¨ ìž¥ë©´ ê²€ìƒ‰
        # filters: {"entities": {"$contains": "ì•¨ë¦¬ìŠ¤"}} ë“±
        search_params = {
            "query_texts": [query],
            "n_results": n_results
        }
        if filters:
            search_params["where"] = filters

        results = self.collection.query(**search_params)
        
        context = "[ê´€ë ¨ ìž¥ë©´ ìš”ì•½]\n"
        for doc, metadata in zip(results['documents'][0], results['metadatas'][0]):
            context += f"ðŸŽ¬ [{metadata['scene_id']}] {metadata['title']}\n"
            context += f"ìš”ì•½: {doc}\n\n"
            
        return context

    def get_entity_history(self, name: str) -> List[Dict]:
        conn = self._get_pg_connection()
        cursor = conn.cursor(cursor_factory=extras.RealDictCursor)
        
        cursor.execute('''
            SELECT e.*, s.summary 
            FROM entities e 
            JOIN scenes s ON e.scene_id = s.scene_id
            WHERE e.name = %s
            ORDER BY e.scene_id ASC
        ''', (name,))
        
        rows = cursor.fetchall()
        cursor.close()
        conn.close()
        return [dict(row) for row in rows]

    def save_error(self, scene_id: str, name: str, err_type: str, desc: str, severity: str = "Medium"):
        conn = self._get_pg_connection()
        cursor = conn.cursor()
        try:
            cursor.execute('''
                INSERT INTO consistency_errors (scene_id, entity_name, error_type, description, severity)
                VALUES (%s, %s, %s, %s, %s)
            ''', (scene_id, name, err_type, desc, severity))
            conn.commit()
        finally:
            cursor.close()
            conn.close()
