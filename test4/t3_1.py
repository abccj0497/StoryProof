# ... (ì•ë¶€ë¶„ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸, ëª¨ë¸ ë¡œë”©, DB í´ë˜ìŠ¤, ì¶”ì¶œ í•¨ìˆ˜ëŠ” ê¸°ì¡´ê³¼ ë™ì¼) ...

# ==========================================
# ğŸ“Š 6. ì •ëŸ‰ì  í‰ê°€ í•¨ìˆ˜ (Hit@k, MRR@k ì¶”ê°€ë¨!)
# ==========================================
def calculate_metrics(db, eval_dataset, k_values=[1, 3, 5]):
    print("\n" + "="*50)
    print(f"ğŸ“Š ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€ ì‹œì‘ (ì´ {len(eval_dataset)}ê°œ ì§ˆë¬¸)")
    print("="*50)
    
    # ì ìˆ˜ ì €ì¥ì†Œ ì´ˆê¸°í™”
    scores = {k: {"hit": 0, "mrr": 0} for k in k_values}
    
    for i, item in enumerate(eval_dataset):
        query = item['query']
        target_id = item['target_parent_id'] # ì •ë‹µ(ì›ë³¸ ë¶€ëª¨ ID)
        
        # ê²€ìƒ‰ ìˆ˜í–‰ (ê°€ì¥ í° kë§Œí¼ ê°€ì ¸ì˜´)
        max_k = max(k_values)
        results = db.search(query, top_k=max_k)
        
        # ê²€ìƒ‰ëœ ê²°ê³¼ë“¤ì˜ Parent ID ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        # (ì£¼ì˜: DB search í•¨ìˆ˜ê°€ parent_idë¥¼ ë¦¬í„´í•˜ë„ë¡ ìˆ˜ì •ë˜ì–´ì•¼ í•¨ -> ì•„ë˜ í´ë˜ìŠ¤ ìˆ˜ì • ì°¸ê³ )
        retrieved_ids = [res['parent_id'] for res in results]
        
        # ë””ë²„ê¹…ìš© ë¡œê·¸ (ì²« 3ê°œë§Œ ì¶œë ¥)
        if i < 3:
            print(f"Q{i+1}: {query}")
            print(f"   -> ì •ë‹µ ID: ...{target_id[-6:]}")
            print(f"   -> ê²€ìƒ‰ IDs: {[rid[-6:] for rid in retrieved_ids]}")
            print("-" * 30)

        # ì§€í‘œ ê³„ì‚°
        for k in k_values:
            # ìƒìœ„ kê°œë§Œ ìë¥´ê¸°
            top_k_ids = retrieved_ids[:k]
            
            # 1. Hit@k ê³„ì‚°
            if target_id in top_k_ids:
                scores[k]["hit"] += 1
                
                # 2. MRR@k ê³„ì‚° (Hití•œ ê²½ìš°ì—ë§Œ ê³„ì‚°)
                # ì •ë‹µì´ ëª‡ ë²ˆì§¸(rank)ì— ìˆëŠ”ì§€ ì°¾ìŒ (0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ +1)
                rank = top_k_ids.index(target_id) + 1
                scores[k]["mrr"] += (1.0 / rank)
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“ˆ [ìµœì¢… í‰ê°€ ê²°ê³¼]")
    total = len(eval_dataset)
    for k in k_values:
        hit_score = scores[k]["hit"] / total
        mrr_score = scores[k]["mrr"] / total
        print(f" -> @{k}: Hit={hit_score:.4f}, MRR={mrr_score:.4f}")
        
    return scores

# ==========================================
# ğŸ”„ [ì¤‘ìš”] DB í´ë˜ìŠ¤ ìˆ˜ì • (parent_id ë°˜í™˜í•˜ë„ë¡)
# ==========================================
# ê¸°ì¡´ ParentChildVectorDBì˜ search ë©”ì„œë“œì—ì„œ resultsì— 'parent_id'ë¥¼ ê¼­ ë„£ì–´ì¤˜ì•¼ í•©ë‹ˆë‹¤.
# ì•„ë˜ ì½”ë“œë¥¼ ê¸°ì¡´ í´ë˜ìŠ¤ì— ë®ì–´ì”Œìš°ì„¸ìš”.
class ParentChildVectorDB:
    def __init__(self):
        self.parents = {} 
        self.children = []

    def add_parent(self, text: str) -> str:
        p_id = str(uuid.uuid4())
        self.parents[p_id] = text
        return p_id

    def add_child(self, parent_id: str, text_to_embed: str, metadata: Dict):
        vector = embed_model.encode(text_to_embed, convert_to_tensor=False)
        self.children.append({
            "parent_id": parent_id,
            "vector": vector,
            "metadata": metadata 
        })

    def search(self, query: str, top_k=3):
        if not self.children: return []
        
        query_vec = embed_model.encode(query, convert_to_tensor=False)
        child_vectors = [c['vector'] for c in self.children]
        
        scores = cosine_similarity([query_vec], child_vectors)[0]
        top_indices = np.argsort(scores)[::-1][:top_k]
        
        results = []
        seen_parents = set()
        
        for idx in top_indices:
            child = self.children[idx]
            p_id = child['parent_id']
            
            if p_id not in seen_parents:
                results.append({
                    "score": float(scores[idx]),
                    "parent_id": p_id, # ğŸ‘ˆ [í•µì‹¬] í‰ê°€ë¥¼ ìœ„í•´ ID ë°˜í™˜ ì¶”ê°€ë¨
                    "matched_scene": child['metadata']['title'],
                    "summary": child['metadata']['summary'],
                    "visual": child['metadata']['visual_description'],
                    "full_context": self.parents[p_id]
                })
                seen_parents.add(p_id)
        
        return results

# ==========================================
# ğŸš€ 7. ë©”ì¸ ì‹¤í–‰ (í‰ê°€ í¬í•¨)
# ==========================================
if __name__ == "__main__":
    # ... (íŒŒì¼ ë¡œë”© ë° ì²­í‚¹ ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼) ...
    # í¸ì˜ìƒ ì—¬ê¸°ë¶€í„° ë¶™ì—¬ë„£ìœ¼ì‹œë©´ ë©ë‹ˆë‹¤.
    
    file_path = "(í…ìŠ¤íŠ¸ë¬¸ì„œ txt) ì´ìƒí•œ ë‚˜ë¼ì˜ ì•¨ë¦¬ìŠ¤ (ìš°ë¦¬ë§ ì˜®ê¹€)(2ì°¨ í¸ì§‘ìµœì¢…)(ë¸”ë¡œê·¸ì—…ë¡œë“œìš© 2018ë…„ ìµœì¢…) 180127.txt"
    if not os.path.exists(file_path):
        with open("test_novel.txt", "w", encoding='utf-8') as f: f.write("í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì…ë‹ˆë‹¤."*500)
        file_path = "test_novel.txt"

    splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=200)
    with open(file_path, 'r', encoding='utf-8') as f: text = f.read()
    parents = splitter.split_text(text)
    
    db = ParentChildVectorDB()
    eval_dataset = [] # ğŸ“ í‰ê°€ ë°ì´í„°ì…‹ (ì§ˆë¬¸, ì •ë‹µID)

    print("\n[Step] ì¸ë±ì‹± ë° í‰ê°€ ë°ì´í„° ìƒì„± ì¤‘...")
    # ì‹œê°„ ê´€ê³„ìƒ 5ê°œ ì²­í¬ë§Œ í…ŒìŠ¤íŠ¸ (ì „ì²´ëŠ” parents ë¡œ ë³€ê²½)
    for i, p_text in enumerate(parents[:5]): 
        print(f"   Processing Chunk {i+1}...")
        p_id = db.add_parent(p_text) # ì •ë‹µ ID ìƒì„±
        scenes = extract_storyboard(p_text)
        
        for scene in scenes:
            queries = " ".join(scene.get('generated_queries', []))
            embed_text = f"{scene['title']} {scene['summary']} {scene['visual_description']} {queries}"
            db.add_child(p_id, embed_text, scene)
            
            # ğŸ“ í‰ê°€ ë°ì´í„° ìë™ ìˆ˜ì§‘ (Self-Correction)
            # LLMì´ ë§Œë“  ì§ˆë¬¸(query)ì˜ ì •ë‹µì€ í˜„ì¬ ì²­í¬(p_id)ì—¬ì•¼ í•¨
            for q in scene.get('generated_queries', []):
                eval_dataset.append({
                    "query": q,
                    "target_parent_id": p_id
                })

    # íŒŒì¼ ì €ì¥ (ìƒëµ ê°€ëŠ¥)
    # save_results_to_json(...)

    # âœ… í‰ê°€ ì‹¤í–‰
    if eval_dataset:
        calculate_metrics(db, eval_dataset, k_values=[1, 3, 5])
    else:
        print("âŒ í‰ê°€í•  ì§ˆë¬¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")