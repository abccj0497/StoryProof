"""
íŒŒì¼ ë¡œë“œ -> ì”¬ ë¶„í•  -> Parent ì²­í‚¹
ê°„ë‹¨í•˜ê³  ê¹”ë”í•œ ë²„ì „
"""

import os
import re
from typing import List, Dict


class DocumentLoader:
    """ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì—ì„œ ë¬¸ì„œ ë¡œë“œ"""
    
    @staticmethod
    def load_txt(file_path: str) -> str:
        """TXT íŒŒì¼ ë¡œë“œ (ìë™ ì¸ì½”ë”© ê°ì§€)"""
        try:
            import chardet
            with open(file_path, 'rb') as f:
                raw_data = f.read()
                result = chardet.detect(raw_data)
                detected_encoding = result['encoding']
                confidence = result['confidence']
                
                if confidence > 0.7 and detected_encoding:
                    try:
                        text = raw_data.decode(detected_encoding)
                        print(f"[OK] íŒŒì¼ ë¡œë“œ: {detected_encoding} (ì‹ ë¢°ë„: {confidence:.2f})")
                        return text
                    except Exception as e:
                        print(f"ë””ì½”ë”© ì‹¤íŒ¨: {detected_encoding}")
                        pass
        except ImportError:
            print("chardet ë¯¸ì„¤ì¹˜ - ê¸°ë³¸ ì¸ì½”ë”©ìœ¼ë¡œ ì‹œë„")
            pass
        
        # Fallback: í•œê¸€ í…ìŠ¤íŠ¸ íŒŒì¼ì˜ ì¼ë°˜ì ì¸ ì¸ì½”ë”© ìˆœì„œ
        encodings = ['utf-8', 'cp949', 'euc-kr', 'utf-16', 'latin-1']
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding, errors='strict') as f:
                    text = f.read()
                    print(f"[OK] íŒŒì¼ ë¡œë“œ: {encoding}")
                    return text
            except (UnicodeDecodeError, UnicodeError, LookupError):
                continue
        
        raise UnicodeDecodeError(
            'unknown', b'', 0, 1,
            f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¸ì½”ë”©: {encodings}"
        )
    
    @staticmethod
    def load_pdf(file_path: str) -> str:
        """PDF íŒŒì¼ ë¡œë“œ"""
        try:
            import PyPDF2
        except ImportError:
            raise ImportError("PyPDF2 í•„ìš”: pip install PyPDF2")
        
        text = []
        with open(file_path, 'rb') as f:
            pdf_reader = PyPDF2.PdfReader(f)
            for page in pdf_reader.pages:
                text.append(page.extract_text())
        return '\n'.join(text)
    
    @staticmethod
    def load_document(file_path: str) -> str:
        """íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ë¬¸ì„œ ë¡œë“œ"""
        ext = os.path.splitext(file_path)[1].lower()
        
        if ext == '.txt':
            return DocumentLoader.load_txt(file_path)
        elif ext == '.pdf':
            return DocumentLoader.load_pdf(file_path)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {ext}")


class SceneChunker:
    """ì”¬ ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„í•  (ìŠ¤ì½”ì–´ë§ ì‹œìŠ¤í…œ)"""
    
    LOCATION_KEYWORDS = [
        'ë°©', 'ì§‘', 'ê±°ë¦¬', 'í•™êµ', 'ì‚¬ë¬´ì‹¤', 'ì¹´í˜', 'ê³µì›', 'ë³‘ì›',
        'ì—­', 'ê³µí•­', 'í˜¸í…”', 'ì‹ë‹¹', 'ìƒì ', 'ë§ˆì„', 'ë„ì‹œ', 'ìˆ²',
        'ì‚°', 'ë°”ë‹¤', 'ê°•', 'ë“¤íŒ', 'ê±´ë¬¼', 'êµì‹¤', 'ë³µë„'
    ]
    
    TIME_TRANSITIONS = [
        'ê·¸ë•Œ', 'ë‹¤ìŒë‚ ', 'ì ì‹œ í›„', 'ê·¸ í›„', 'ì´íŠ¿ë‚ ', 'ë©°ì¹  í›„',
        'ë‹¤ìŒ', 'ê·¸ë‚ ', 'ì•„ì¹¨', 'ì €ë…', 'ë°¤', 'ìƒˆë²½', 'ì˜¤í›„',
        'í•œì°¸ í›„', 'ê³§', 'ì´ìœ½ê³ ', 'ê·¸ëŸ¬ì', 'ìˆœê°„'
    ]
    
    def __init__(self, threshold: int = 30):
        self.threshold = threshold
    
    def contains_new_location(self, sentence: str) -> bool:
        """ë¬¸ì¥ì— ì¥ì†Œ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸"""
        return any(loc in sentence for loc in self.LOCATION_KEYWORDS)
    
    def split_into_scenes(self, text: str) -> List[str]:
        """ìŠ¤ì½”ì–´ë§ ì‹œìŠ¤í…œìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì”¬ ë‹¨ìœ„ë¡œ ë¶„í• """
        # ë¬¸ì¥ ë‹¨ìœ„ ë¶„í• 
        sentences = re.split(r'([.!?]\s+)', text)
        
        merged_sentences = []
        for i in range(0, len(sentences) - 1, 2):
            if i + 1 < len(sentences):
                merged_sentences.append(sentences[i] + sentences[i + 1])
            else:
                merged_sentences.append(sentences[i])
        
        scenes = []
        current_scene = []
        score = 0
        
        for sent in merged_sentences:
            if not sent.strip():
                continue
            
            # 1. ë¬¼ë¦¬ì  ê¸°í˜¸ ì²´í¬
            if "***" in sent or "---" in sent or "###" in sent:
                score += 10
            
            # 2. ì¥ì†Œ ë³€í™” ì²´í¬
            if self.contains_new_location(sent):
                score += 5
            
            # 3. ì‹œê°„ ì „í™˜ ë¶€ì‚¬ì–´ ì²´í¬
            if any(word in sent for word in self.TIME_TRANSITIONS):
                score += 4
            
            # 4. ëŒ€í™” ì¢…ë£Œ í›„ ì„œìˆ  ì „í™˜ ì²´í¬
            if re.search(r'["\']\s*[.!?]\s+[^"\']+', sent):
                score += 3
            
            current_scene.append(sent)
            
            # ì ìˆ˜ ì„ê³„ê°’ ë„ë‹¬ ì‹œ ì”¬ í™•ì •
            if score >= self.threshold:
                scenes.append(" ".join(current_scene))
                current_scene = []
                score = 0
        
        # ë‚¨ì€ ë¬¸ì¥ ì²˜ë¦¬
        if current_scene:
            scenes.append(" ".join(current_scene))
        
        return scenes


class ParentChunker:
    """ì”¬ì„ Parent ì²­í¬ë¡œ ë³€í™˜"""
    
    @staticmethod
    def create_parent_chunks(scenes: List[str]) -> List[Dict]:
        """ê° ì”¬ì„ Parent ì²­í¬ë¡œ ìƒì„±"""
        parent_chunks = []
        
        for scene_idx, scene in enumerate(scenes):
            parent_chunk = {
                'id': f"scene_{scene_idx}",
                'text': scene,
                'scene_index': scene_idx,
                'char_count': len(scene)
            }
            parent_chunks.append(parent_chunk)
        
        return parent_chunks


def process_file(file_path: str, scene_threshold: int = 7) -> List[Dict]:
    """
    íŒŒì¼ ì…ë ¥ -> ì”¬ ë¶„í•  -> Parent ì²­í‚¹
    
    Args:
        file_path: ì…ë ¥ íŒŒì¼ ê²½ë¡œ
        scene_threshold: ì”¬ ë¶„í•  ì„ê³„ê°’
    
    Returns:
        Parent ì²­í¬ ë¦¬ìŠ¤íŠ¸
    """
    
    print("=" * 60)
    print("íŒŒì¼ ë¡œë“œ â†’ ì”¬ ë¶„í•  â†’ Parent ì²­í‚¹")
    print("=" * 60)
    
    # 1. íŒŒì¼ ë¡œë“œ
    print(f"\n[1/3] íŒŒì¼ ë¡œë“œ: {file_path}")
    loader = DocumentLoader()
    text = loader.load_document(file_path)
    print(f"[OK] {len(text):,} ì ë¡œë“œ ì™„ë£Œ")
    
    # 2. ì”¬ ë¶„í• 
    print(f"\n[2/3] ì”¬ ë¶„í•  (ì„ê³„ê°’={scene_threshold})")
    scene_chunker = SceneChunker(threshold=scene_threshold)
    scenes = scene_chunker.split_into_scenes(text)
    print(f"[OK] {len(scenes):,}ê°œ ì”¬ ìƒì„±")
    
    # 3. Parent ì²­í‚¹
    print(f"\n[3/3] Parent ì²­í¬ ìƒì„±")
    parent_chunks = ParentChunker.create_parent_chunks(scenes)
    print(f"[OK] {len(parent_chunks):,}ê°œ Parent ì²­í¬ ìƒì„± ì™„ë£Œ")
    
    print("\n" + "=" * 60)
    
    return parent_chunks


def print_chunks_info(chunks: List[Dict]) -> None:
    """ì²­í¬ ì •ë³´ ì¶œë ¥"""
    print("\nğŸ“Š ì²­í¬ ì •ë³´:")
    print(f"  - ì´ ê°œìˆ˜: {len(chunks)}")
    
    if chunks:
        char_counts = [c['char_count'] for c in chunks]
        print(f"  - í‰ê·  í¬ê¸°: {sum(char_counts) / len(chunks):.0f} ì")
        print(f"  - ìµœì†Œ í¬ê¸°: {min(char_counts)} ì")
        print(f"  - ìµœëŒ€ í¬ê¸°: {max(char_counts)} ì")
        print(f"\n  ì²« ë²ˆì§¸ ì²­í¬ ìƒ˜í”Œ:")
        print(f"    ID: {chunks[0]['id']}")
        print(f"    í¬ê¸°: {chunks[0]['char_count']} ì")
        print(f"    ë‚´ìš©: {chunks[0]['text'][:100]}...")


if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì‹œ
    import glob
    
    # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ .txt íŒŒì¼ ì°¾ê¸°
    script_dir = os.path.dirname(__file__) or '.'
    txt_files = glob.glob(os.path.join(script_dir, "*.txt"))
    
    if txt_files:
        input_file = txt_files[0]
        print(f"ë°œê²¬ëœ íŒŒì¼: {input_file}")
        
        # Parent ì²­í‚¹ ì‹¤í–‰
        parent_chunks = process_file(input_file, scene_threshold=7)
        
        # ê²°ê³¼ ì¶œë ¥
        print_chunks_info(parent_chunks)
        
        # ì „ì²´ ì²­í¬ ë‚´ìš© ì¶œë ¥ (ì˜µì…˜)
        # for chunk in parent_chunks:
        #     print(f"\n{chunk['id']}: {chunk['text'][:200]}...")
    else:
        print("âŒ .txt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
