import os
import json
import time
from typing import List, Dict, Any

# [ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ]
import google.generativeai as genai
import chromadb
from chromadb.utils import embedding_functions
from sentence_transformers import SentenceTransformer

# ==========================================
# [ì„¤ì • ì˜ì—­] API í‚¤ ë° ëª¨ë¸ ì„¤ì •
# ==========================================
# Google API Key ì„¤ì • (í™˜ê²½ë³€ìˆ˜ í˜¹ì€ ì§ì ‘ ì…ë ¥)
os.environ["GOOGLE_API_KEY"] = "YOUR_GOOGLE_API_KEY"  # <- ì—¬ê¸°ì— í‚¤ ì…ë ¥
MODEL_NAME = "gemini-2.0-flash"  # (2.5ê°€ ì•„ì§ API ë°°í¬ ì „ì´ë¼ë©´ 2.0 Flash ì‚¬ìš© ì¶”ì²œ)

# ì„ë² ë”© ëª¨ë¸ ì„¤ì • (BGE-M3)
EMBEDDING_MODEL_NAME = "BAAI/bge-m3"

# ==========================================
# [Class 1] AI ìŠ¤í† ë¦¬ ë¶„ì„ê¸° (Gemini)
# ==========================================
class StoryAnalyzer:
    def __init__(self, api_key: str):
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(
            model_name=MODEL_NAME,
            generation_config={"response_mime_type": "application/json"} # JSON ê°•ì œ ì¶œë ¥
        )

    def analyze_scene(self, scene_text: str, scene_id: str) -> Dict:
        """
        Geminië¥¼ ì´ìš©í•´ ì†Œì„¤ ì›ë¬¸ì„ 3 Layer êµ¬ì¡°(Meta, Wiki, Vector)ë¡œ ë¶„ì„
        """
        prompt = f"""
        ë‹¹ì‹ ì€ ì†Œì„¤ ì§‘í•„ì„ ë•ëŠ” 'ìŠ¤í† ë¦¬ ì–´ì‹œìŠ¤í„´íŠ¸'ì…ë‹ˆë‹¤.
        ì•„ë˜ ì†Œì„¤ì˜ í•œ ì¥ë©´(Scene)ì„ ì½ê³ , ì§‘í•„ì— í•„ìš”í•œ ì •ë³´ë¥¼ ì²´ê³„ì ì¸ JSON í¬ë§·ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.

        [ë¶„ì„ ëª©í‘œ]
        1. Meta Layer: í•„í„°ë§ì„ ìœ„í•œ ì‹œê°„, ì¥ì†Œ, ë“±ì¥ì¸ë¬¼ ë¦¬ìŠ¤íŠ¸
        2. Wiki Layer: ë“±ì¥í•œ ê³ ìœ ëª…ì‚¬(ì¸ë¬¼, ì¥ì†Œ, ì‚¬ë¬¼)ì— ëŒ€í•œ ë°±ê³¼ì‚¬ì „ì‹ ìƒì„¸ ë¶„ì„ (íŠ¸ë¦¬ êµ¬ì¡°)
        3. Vector Layer: ë‚˜ì¤‘ì— "ì² ìˆ˜ê°€ ì™œ í™”ëƒˆì–´?" ê°™ì€ ì§ˆë¬¸ì— ê²€ìƒ‰ì´ ì˜ ë˜ë„ë¡, ì¸ê³¼ê´€ê³„ê°€ ëª…í™•í•œ 'ì••ì¶• ìš”ì•½ë¬¸' ì‘ì„±

        [ì…ë ¥ í…ìŠ¤íŠ¸]
        {scene_text}

        [ì¶œë ¥ JSON í¬ë§· (ì—„ìˆ˜)]
        {{
          "scene_id": "{scene_id}",
          "title": "í•œ ì¤„ ì œëª©",
          "meta": {{
            "time": "ì‹œê°„ì  ë°°ê²½ (ì˜ˆ: ì €ë…, í•´ì§ˆë…˜)",
            "place": "ê³µê°„ì  ë°°ê²½",
            "characters": ["ë“±ì¥ì¸ë¬¼1", "ë“±ì¥ì¸ë¬¼2"]
          }},
          "wiki_entities": [
            {{
              "name": "ì´ë¦„",
              "category": "ì¸ë¬¼/ì¥ì†Œ/ë¬¼í’ˆ/ì‚¬ê±´",
              "sub_category": "ì„¸ë¶€ ë¶„ë¥˜ (ì˜ˆ: ì£¼ì—°, ìƒì—…ì‹œì„¤, ê·€ì¤‘í’ˆ)",
              "description": "ìƒì„¸ ì„¤ëª… (ì™¸ì–‘, íŠ¹ì§•, í˜„ì¬ ìƒíƒœ)",
              "action": "ì´ ì¥ë©´ì—ì„œì˜ ì£¼ìš” í–‰ë™ (ì¸ë¬¼ì¸ ê²½ìš°)"
            }}
          ],
          "dense_summary": "ê²€ìƒ‰ ìµœì í™” ìš”ì•½ë¬¸ (ì£¼ì–´, ëª©ì ì–´, ì›ì¸, ê²°ê³¼ë¥¼ ëª…ì‹œí•˜ì—¬ ì„œìˆ )"
        }}
        """
        
        try:
            response = self.model.generate_content(prompt)
            return json.loads(response.text)
        except Exception as e:
            print(f"âŒ AI ë¶„ì„ ì‹¤íŒ¨ ({scene_id}): {e}")
            # ì‹¤íŒ¨ ì‹œ ë¹ˆ í…œí”Œë¦¿ ë°˜í™˜í•˜ì—¬ íŒŒì´í”„ë¼ì¸ ëŠê¹€ ë°©ì§€
            return {
                "scene_id": scene_id, "title": "ë¶„ì„ ì‹¤íŒ¨", 
                "meta": {"time": "", "place": "", "characters": []},
                "wiki_entities": [], "dense_summary": scene_text[:200]
            }

# ==========================================
# [Class 2] ì‘ê°€ ë°”ì´ë¸” DB (Chroma + BGE-M3)
# ==========================================
class BibleDatabase:
    def __init__(self, db_path="./novel_bible_db"):
        # 1. BGE-M3 ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (SentenceTransformer ì‚¬ìš©)
        print(f"â³ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘ ({EMBEDDING_MODEL_NAME})...")
        self.embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)
        
        # 2. ChromaDB í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (Persistent: íŒŒì¼ë¡œ ì €ì¥)
        self.client = chromadb.PersistentClient(path=db_path)
        
        # 3. ì»¬ë ‰ì…˜ ìƒì„± (ì„ë² ë”© í•¨ìˆ˜ ì»¤ìŠ¤í…€ ì—°ê²°)
        # ChromaDBëŠ” ê¸°ë³¸ì´ ì˜ë¬¸ ëª¨ë¸ì´ë¯€ë¡œ, BGE-M3ë¥¼ ì“°ëŠ” ì»¤ìŠ¤í…€ í•¨ìˆ˜ ì •ì˜ í•„ìš”
        self.collection = self.client.get_or_create_collection(
            name="story_bible",
            metadata={"hnsw:space": "cosine"} # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì‚¬ìš©
        )

    def add_storyboard(self, storyboard: Dict):
        """
        ë¶„ì„ëœ ìŠ¤í† ë¦¬ë³´ë“œ JSONì„ DBì— ì €ì¥
        """
        # Chroma MetadataëŠ” List/Dictë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        metadata = {
            "scene_id": storyboard['scene_id'],
            "title": storyboard['title'],
            "time": storyboard['meta']['time'],
            "place": storyboard['meta']['place'],
            "characters_str": ", ".join(storyboard['meta']['characters']), # í•„í„°ë§ìš© ë¬¸ìì—´
            "full_json": json.dumps(storyboard, ensure_ascii=False) # ë‚˜ì¤‘ì— êº¼ë‚´ë³¼ ì „ì²´ ë°ì´í„°
        }

        # ì„ë² ë”© ìƒì„± (dense_summary ê¸°ì¤€)
        vector = self.embedding_model.encode(storyboard['dense_summary']).tolist()

        self.collection.add(
            ids=[storyboard['scene_id']],
            embeddings=[vector],
            metadatas=[metadata],
            documents=[storyboard['dense_summary']]
        )
        print(f"âœ… DB ì €ì¥ ì™„ë£Œ: {storyboard['scene_id']} - {storyboard['title']}")

    def search_vector(self, query: str, top_k: int = 3):
        """
        Vector Layer ê²€ìƒ‰: ì§ˆë¬¸(Query)ê³¼ ìœ ì‚¬í•œ ì¥ë©´ ì°¾ê¸°
        """
        query_vector = self.embedding_model.encode(query).tolist()
        
        results = self.collection.query(
            query_embeddings=[query_vector],
            n_results=top_k
        )
        
        print(f"\nğŸ” ê²€ìƒ‰ ê²°ê³¼: '{query}'")
        for i in range(len(results['ids'][0])):
            meta = results['metadatas'][0][i]
            dist = results['distances'][0][i]
            print(f"  [{i+1}] {meta['title']} (ìœ ì‚¬ë„: {1-dist:.4f})")
            print(f"      - ìš”ì•½: {results['documents'][0][i][:80]}...")
            
    def aggregate_by_character(self, char_name: str):
        """
        Meta Layer ì§‘ê³„: íŠ¹ì • ì¸ë¬¼ì´ ë“±ì¥í•˜ëŠ” ëª¨ë“  ì¥ë©´ ì¡°íšŒ (DB í•„í„°ë§)
        """
        # Note: Chromaì˜ contains í•„í„°ê°€ ì œí•œì ì´ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ì „ì²´ë¥¼ ê°€ì ¸ì™€ì„œ Python í•„í„°ë§ ì˜ˆì‹œ
        # ì‹¤ì œ ëŒ€ê·œëª¨ êµ¬ì¶• ì‹œì—ëŠ” Metadataì— 'char_1', 'char_2' ì‹ìœ¼ë¡œ ë„£ê±°ë‚˜ ë³„ë„ RDBMS ì‚¬ìš© ê¶Œì¥
        all_data = self.collection.get()
        
        found_scenes = []
        if all_data['ids']:
            for i, meta in enumerate(all_data['metadatas']):
                if char_name in meta['characters_str']:
                    full_data = json.loads(meta['full_json'])
                    found_scenes.append(full_data)
        
        print(f"\nğŸ“‚ '{char_name}' ë“±ì¥ ì¥ë©´ ëª¨ìŒ ({len(found_scenes)}ê±´):")
        for scene in found_scenes:
            print(f"  - [{scene['scene_id']}] {scene['title']} (@{scene['meta']['place']})")
            # í•´ë‹¹ ì¸ë¬¼ì˜ í–‰ë™(Action)ë§Œ ë½‘ì•„ì„œ ë³´ì—¬ì£¼ê¸° (Wiki Layer í™œìš©)
            for entity in scene['wiki_entities']:
                if entity['name'] == char_name:
                    print(f"    â”” í–‰ë™: {entity.get('action', 'ì—†ìŒ')}")

# ==========================================
# [Main Execution] 1ë²ˆ ì½”ë“œì™€ ì—°ê²°
# ==========================================

# 1ë²ˆ ì½”ë“œì˜ í´ë˜ìŠ¤ë“¤ì„ ê°€ì ¸ì™”ë‹¤ê³  ê°€ì • (ìœ„ì— ì‘ì„±í•´ì£¼ì‹  ì½”ë“œ)
# ì‹¤ì œ ì‚¬ìš©ì‹œëŠ” 'from chunking_module import process_file' í˜•íƒœë¡œ ì‚¬ìš©
# ì—¬ê¸°ì„œëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê°€ìƒì˜ ê²°ê³¼ê°’ì„ ì‚¬ìš©í•˜ê±°ë‚˜, ìœ„ ì½”ë“œë¥¼ í•©ì³ì•¼ í•¨.

def main():
    # 1. ì†Œì„¤ íŒŒì¼ ì²˜ë¦¬ (1ë²ˆ ì½”ë“œ ì‹¤í–‰)
    # ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.
    input_file = "sample_novel.txt" 
    
    # íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„° ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
    if not os.path.exists(input_file):
        with open(input_file, "w", encoding="utf-8") as f:
            f.write("ì² ìˆ˜ê°€ ë´‰í‰ ì¥í„° ì£¼ë§‰ì— ë“¤ì–´ì„°ë‹¤. ë‚ ì€ ì´ë¯¸ ì €ë¬¼ì–´ ìˆì—ˆë‹¤. 'ì£¼ëª¨! ì—¬ê¸° êµ­ë°¥ í•œ ê·¸ë¦‡ ì£¼ì†Œ.' ê·¸ë•Œ ì˜í¬ê°€ ë¬¸ì„ ë°•ì°¨ê³  ë“¤ì–´ì™”ë‹¤. ê·¸ë…€ì˜ ì†ì—ëŠ” ë¶‰ì€ ì˜¥êµ¬ìŠ¬ì´ ë“¤ë ¤ ìˆì—ˆë‹¤. 'ì² ìˆ˜, ë„¤ê°€ ê°íˆ...' ì˜í¬ëŠ” ë§ì„ ì‡ì§€ ëª»í–ˆë‹¤.")
    
    # [Step 1] ì²­í‚¹ (ì‚¬ìš©ìê°€ ì œê³µí•œ ë¡œì§ ì‚¬ìš©)
    # parent_chunks = process_file(input_file) -> 1ë²ˆ ì½”ë“œ í•¨ìˆ˜ í˜¸ì¶œ
    # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¥¼ ìœ„í•´ 1ë²ˆ ì½”ë“œì˜ ì¶œë ¥ í˜•íƒœë¥¼ ëª¨ì‚¬í•¨
    parent_chunks = [
        {
            "id": "scene_001",
            "text": "ì² ìˆ˜ê°€ ë´‰í‰ ì¥í„° ì£¼ë§‰ì— ë“¤ì–´ì„°ë‹¤. ë‚ ì€ ì´ë¯¸ ì €ë¬¼ì–´ ìˆì—ˆë‹¤. 'ì£¼ëª¨! ì—¬ê¸° êµ­ë°¥ í•œ ê·¸ë¦‡ ì£¼ì†Œ.' ê·¸ë•Œ ì˜í¬ê°€ ë¬¸ì„ ë°•ì°¨ê³  ë“¤ì–´ì™”ë‹¤. ê·¸ë…€ì˜ ì†ì—ëŠ” ë¶‰ì€ ì˜¥êµ¬ìŠ¬ì´ ë“¤ë ¤ ìˆì—ˆë‹¤. 'ì² ìˆ˜, ë„¤ê°€ ê°íˆ...' ì˜í¬ëŠ” ë§ì„ ì‡ì§€ ëª»í•˜ê³  ê±°ì¹œ ìˆ¨ì„ ëª°ì•„ì‰¬ì—ˆë‹¤. ì£¼ë§‰ ì•ˆì˜ ì‚¬ëŒë“¤ì´ ëª¨ë‘ ê·¸ë“¤ì„ ì³ë‹¤ë³´ì•˜ë‹¤.",
            "scene_index": 0
        }
    ]

    # [Step 2 & 3] AI ë¶„ì„ ë° DB ì €ì¥
    analyzer = StoryAnalyzer(api_key=os.environ["GOOGLE_API_KEY"])
    bible_db = BibleDatabase()

    print("\nğŸš€ ìŠ¤í† ë¦¬ ë¶„ì„ ë° DB êµ¬ì¶• ì‹œì‘...")
    for chunk in parent_chunks:
        # AIì—ê²Œ ë¶„ì„ ìš”ì²­
        storyboard = analyzer.analyze_scene(chunk['text'], chunk['id'])
        
        # DBì— ì €ì¥
        bible_db.add_storyboard(storyboard)
        
        # API ì†ë„ ì œí•œ ê³ ë ¤ (Tierì— ë”°ë¼ ì¡°ì ˆ)
        time.sleep(1) 

    print("\n" + "="*50)
    print("ğŸ“š ì‘ê°€ ë°”ì´ë¸”(Writer's Bible) ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("="*50)

    # [Step 4-1] ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ (Vector Layer)
    # ì§ˆë¬¸: ì›ë¬¸ì—ëŠ” "ì‹¸ì› ë‹¤"ëŠ” ë§ì´ ì—†ì–´ë„, ë¬¸ë§¥ìƒ ê°ˆë“± ìƒí™©ì„ ì°¾ìŒ
    bible_db.search_vector("ë‘ ë‚¨ë…€ê°€ ê°ˆë“±í•˜ëŠ” ê¸´ì¥ëœ ìƒí™©")

    # [Step 4-2] ì¸ë¬¼ ê¸°ë°˜ ì§‘ê³„ (Meta & Wiki Layer)
    # ì˜í¬ê°€ ë‚˜ì˜¨ ì¥ë©´ê³¼ ê·¸ë•Œì˜ í–‰ë™ë§Œ ì‹¹ ê¸ì–´ì˜¤ê¸°
    bible_db.aggregate_by_character("ì˜í¬")

if __name__ == "__main__":
    main()