import os
import re
import json
import time
from typing import List, Dict, Any
from collections import defaultdict
from google import genai
from google.genai import types

# =========================================================
# [ì„¤ì •] API í‚¤ì™€ íŒŒì¼ëª…
# =========================================================
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "AIzaSyA0ADjqddqoa6ipqXNFaO5i4c2_-ByY5l4") 
INPUT_FILE_NAME = "KR_fantasy_alice.txt" 

LLM_MODEL_NAME = "gemini-2.5-flash"
OUTPUT_DIR = "output_v2" 
SCENE_DIR = os.path.join(OUTPUT_DIR, "scenes")

def create_output_dirs():
    if not os.path.exists(SCENE_DIR):
        os.makedirs(SCENE_DIR)

# =========================================================
# [PART 1] í•˜ì´ë¸Œë¦¬ë“œ ì²­ì»¤ V2 (Sliding Window ì ìš©)
# =========================================================
class HybridSceneChunker:
    LOCATION_KEYWORDS = ['ë°©', 'ì§‘', 'ê±°ë¦¬', 'ìˆ²', 'êµ´', 'ì •ì›', 'í™€', 'ë°”ë‹¤', 'ì§‘ì•ˆ', 'ë‚˜ë¬´', 'ì„±', 'ë§ˆì„', 'êµì‹¤', 'ë³µë„', 'ì°½ê°€', 'ë˜ì „', 'ì™•ê¶']
    TIME_TRANSITIONS = ['ê·¸ë•Œ', 'ë‹¤ìŒë‚ ', 'ì ì‹œ í›„', 'ì•„ì¹¨', 'ì €ë…', 'ë°¤', 'ê°‘ìê¸°', 'ë©°ì¹  ë’¤', 'ëª‡ ì‹œê°„ í›„', 'ìƒˆë²½', 'ì˜¤í›„', 'ê³„ì ˆì´', 'ì‹œê°„ì´']
    CHAPTER_PATTERNS = [r"^\s*ì œ\s*[0-9]+\s*[ì¥í™”í¸]", r"^\s*Chapter\s*[0-9]+", r"^\s*\*\*\*"]

    def __init__(self, target_chars=3500, min_chars=1000, threshold=5, overlap_chars=200):
        self.target_chars = target_chars
        self.min_chars = min_chars
        self.threshold = threshold
        self.overlap_chars = overlap_chars 

    def _calculate_score(self, text_segment):
        score = 0
        if any(k in text_segment for k in self.LOCATION_KEYWORDS): score += 5
        if any(k in text_segment for k in self.TIME_TRANSITIONS): score += 4
        return score

    def split_content(self, text: str) -> List[str]:
        text = text.replace('\r\n', '\n')
        paragraphs = re.split(r'\n\s*\n', text)
        final_scenes, current_scene, current_len = [], [], 0
        
        for para in paragraphs:
            para = para.strip()
            if not para: continue
            
            is_chapter = any(re.match(p, para, re.IGNORECASE) for p in self.CHAPTER_PATTERNS)
            score = self._calculate_score(para[:50])

            if (is_chapter and current_len > 0) or \
               (score >= self.threshold and current_len >= self.min_chars) or \
               (current_len + len(para) > self.target_chars):
                
                full_scene_text = "\n\n".join(current_scene)
                final_scenes.append(full_scene_text)
                
                # ë‹¤ìŒ ì”¬ ë¬¸ë§¥ ìœ ì§€ë¥¼ ìœ„í•´ ëë¶€ë¶„ ì˜¤ë²„ë©
                current_scene = [full_scene_text[-self.overlap_chars:]] if len(full_scene_text) > self.overlap_chars else []
                current_scene.append(para)
                current_len = len(para)
            else:
                current_scene.append(para)
                current_len += len(para)

        if current_scene: final_scenes.append("\n\n".join(current_scene))
        return final_scenes

# =========================================================
# [PART 2] ìŠ¤í† ë¦¬ë³´ë“œ ì¶”ì¶œê¸° V2 (Deep Analysis)
# =========================================================
class StoryAnalyzer:
    def __init__(self, api_key):
        self.client = genai.Client(api_key=api_key)

    def analyze(self, chunk: Dict) -> Dict:
        prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ ì†Œì„¤ í¸ì§‘ìì…ë‹ˆë‹¤. ì•„ë˜ ì†Œì„¤ ì›ë¬¸ì„ ë¶„ì„í•˜ì—¬ JSONìœ¼ë¡œ êµ¬ì¡°í™”í•˜ì„¸ìš”.
        
        [ì£¼ì˜ì‚¬í•­]
        1. 'Character'ì—ëŠ” ì‹¤ì œ ë“±ì¥ì¸ë¬¼ë§Œ í¬í•¨í•˜ì„¸ìš”. (ì‘ê°€ëª…, ì±… ì œëª© ì œì™¸)
        2. 'summary'ëŠ” ìœ¡í•˜ì›ì¹™ì— ë”°ë¼ ì„œì‚¬ íë¦„ ìœ„ì£¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        3. 'atmosphere'ëŠ” ì´ ì¥ë©´ì˜ ë¶„ìœ„ê¸°ë‚˜ ë“±ì¥ì¸ë¬¼ì˜ ì£¼ëœ ê°ì •ì„ ë¬˜ì‚¬í•˜ì„¸ìš”.

        [TEXT]
        {chunk['text'][:4500]}
        
        [OUTPUT JSON FORMAT]
        {{
          "scene_id": "{chunk['id']}",
          "book_info": {{ "title": "ì†Œì„¤ ì œëª©", "author": "ì‘ê°€ ì´ë¦„" }},
          "scene_title": "ì¥ë©´ ì†Œì œëª©",
          "summary": "ì¥ë©´ ìš”ì•½ (3-5ë¬¸ì¥)",
          "atmosphere": "ë¶„ìœ„ê¸°/ê°ì •ì„ ",
          "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"],
          "entities": [
            {{ "name": "ì´ë¦„", "type": "Character/Place/Item", "desc": "ì™¸ëª¨/ì„±ê²©/íŠ¹ì§•", "action": "ì£¼ìš” í–‰ë™/ì—­í• " }}
          ]
        }}
        """
        try:
            response = self.client.models.generate_content(
                model=LLM_MODEL_NAME,
                contents=prompt,
                config=types.GenerateContentConfig(response_mime_type="application/json")
            )
            result = json.loads(response.text)
            if isinstance(result, list): result = result[0]
            if 'atmosphere' not in result: result['atmosphere'] = "N/A"
            if 'keywords' not in result: result['keywords'] = []
            return result
        except Exception as e:
            print(f"âš ï¸ ë¶„ì„ ì‹¤íŒ¨ ({chunk['id']}): {e}")
            return None

# =========================================================
# [PART 3] ë°”ì´ë¸” ìƒì„±ê¸° V2 (í‘œ ë””ìì¸ & TOC)
# =========================================================
class WikiGenerator:
    @staticmethod
    def save_report_to_file(storyboard_list: List[Dict]):
        file_path = os.path.join(OUTPUT_DIR, "writer_bible_v2.md")
        if not storyboard_list: return

        first_valid = storyboard_list[0] if not isinstance(storyboard_list[0], list) else storyboard_list[0][0]
        book_title = first_valid.get('book_info', {}).get('title', 'Unknown Title')
        author = first_valid.get('book_info', {}).get('author', 'Unknown Author')
        
        wiki = defaultdict(lambda: defaultdict(list))
        total_keywords = set()
        
        for scene in storyboard_list:
            if isinstance(scene, list): scene = scene[0]
            s_id = scene.get('scene_id', 'unknown')
            for k in scene.get('keywords', []): total_keywords.add(k)
            for ent in scene.get('entities', []):
                if ent['name'] in [book_title, author, "Project", "Book", "Unknown"]: continue
                wiki[ent['type']][ent['name']].append({
                    "scene": s_id, "desc": ent['desc'], "action": ent['action']
                })

        with open(file_path, "w", encoding="utf-8") as f:
            f.write(f"# ğŸ“˜ {book_title} - ì„¤ì • ìë£Œì§‘ (V2)\n")
            f.write(f"**Generated by StoryProof AI (Advanced Mode)**\n\n")
            f.write(f"- **ì‘ê°€:** {author}\n")
            f.write(f"- **ì´ ë¶„ì„ ì”¬:** {len(storyboard_list)}ê°œ\n")
            f.write(f"- **ì¶”ì¶œ í‚¤ì›Œë“œ:** {', '.join(list(total_keywords)[:10])} ...\n\n")
            
            f.write("## ğŸ“‘ ëª©ì°¨ (Table of Contents)\n")
            f.write("1. [ìŠ¤í† ë¦¬ë¼ì¸ (Storyline)](#1-ìŠ¤í† ë¦¬ë¼ì¸-storyline)\n")
            f.write("2. [ë“±ì¥ì¸ë¬¼ (Characters)](#2-ë“±ì¥ì¸ë¬¼-characters)\n")
            f.write("3. [ì•„ì´í…œ & ì¥ì†Œ (Items & Places)](#3-ì•„ì´í…œ--ì¥ì†Œ-items--places)\n\n---\n\n")
            
            f.write(f"## 1. ìŠ¤í† ë¦¬ë¼ì¸ (Storyline)\n")
            for scene in storyboard_list:
                if isinstance(scene, list): scene = scene[0]
                f.write(f"### ğŸ¬ **[{scene.get('scene_id')}] {scene.get('scene_title','')}**\n")
                f.write(f"- **ë¶„ìœ„ê¸°:** {scene.get('atmosphere', 'N/A')}\n")
                f.write(f"- **ìš”ì•½:** {scene.get('summary','')}\n\n")
            f.write("---\n\n")

            f.write(f"## 2. ë“±ì¥ì¸ë¬¼ (Characters)\n")
            char_items = wiki.get("Character", {})
            if not char_items:
                f.write("_ë°ì´í„° ì—†ìŒ_\n")
            else:
                f.write("| ì´ë¦„ | íŠ¹ì§• | í–‰ë™ | ë“±ì¥ ì”¬ |\n|---|---|---|---|\n")
                for name, details in char_items.items():
                    all_desc = list(set([d['desc'] for d in details if d['desc']]))
                    main_desc = all_desc[0] if all_desc else "-"
                    if len(all_desc) > 1: main_desc += f" ì™¸ {len(all_desc)-1}ê±´"
                    
                    all_action = list(set([d['action'] for d in details if d['action']]))
                    main_action = all_action[0] if all_action else "-"
                    
                    scenes = ", ".join(sorted(list(set([d['scene'].replace('scene_', '') for d in details]))))
                    f.write(f"| **{name}** | {main_desc} | {main_action} | {scenes} |\n")
            f.write("\n---\n\n")

            f.write(f"## 3. ì•„ì´í…œ & ì¥ì†Œ (Items & Places)\n")
            for key in ["Item", "Place"]:
                items = wiki.get(key, {})
                if not items: continue
                f.write(f"### ğŸ”¹ {key}\n")
                for name, details in items.items():
                    desc_set = list(set([d['desc'] for d in details if d['desc']]))
                    f.write(f"- **{name}**: {desc_set[0] if desc_set else 'ì„¤ëª… ì—†ìŒ'}\n")
                f.write("\n")
        print(f"âœ… V2 ë°”ì´ë¸” ìƒì„± ì™„ë£Œ: {file_path}")

# =========================================================
# [ë©”ì¸ ì‹¤í–‰]
# =========================================================
def main():
    create_output_dirs()
    if not os.path.exists(INPUT_FILE_NAME):
        print(f"âŒ {INPUT_FILE_NAME} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."); return

    print(f"ğŸ“– ì†Œì„¤ íŒŒì¼ì„ ì½ëŠ” ì¤‘: {INPUT_FILE_NAME}")
    try:
        with open(INPUT_FILE_NAME, 'r', encoding='utf-8') as f: text = f.read()
    except:
        with open(INPUT_FILE_NAME, 'r', encoding='cp949') as f: text = f.read()

    print("âœ‚ï¸  í•˜ì´ë¸Œë¦¬ë“œ ì²­í‚¹ V2 (Smart Split) ì§„í–‰ ì¤‘...")
    chunks = HybridSceneChunker().split_content(text)
    scene_data = [{'id': f"scene_{i+1:03d}", 'text': txt} for i, txt in enumerate(chunks)]

    # =========================================================
    # [ì¶”ê°€ë¨] ì²­í‚¹ëœ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ë¡œì§
    # =========================================================
    print(f"ğŸ’¾ ì²­í‚¹ëœ íŒŒì¼ ì €ì¥ ì¤‘... ({SCENE_DIR})")
    for scene in scene_data:
        file_name = f"{scene['id']}.txt"
        file_path = os.path.join(SCENE_DIR, file_name)
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(scene['text'])
    # =========================================================

    analyzer = StoryAnalyzer(GOOGLE_API_KEY)
    results = []
    print(f"ğŸš€ ì‹¬ì¸µ ë¶„ì„ ì‹œì‘ (ì´ {len(scene_data)}ê°œ ì”¬ / Model: {LLM_MODEL_NAME})")

    for i, chunk in enumerate(scene_data):
        print(f"  â–¶ [{i+1}/{len(scene_data)}] {chunk['id']} ë¶„ì„ ì¤‘... (Deep Analysis)")
        res = analyzer.analyze(chunk)
        if res: results.append(res)
        time.sleep(1.2)

    if results:
        with open(os.path.join(OUTPUT_DIR, "storyboard_analysis_v2.json"), "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        WikiGenerator.save_report_to_file(results)
    else:
        print("âŒ ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()