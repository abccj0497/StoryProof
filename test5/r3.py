import os
import re
import json
import time
from typing import List, Dict, Any
from collections import defaultdict
from google import genai
from google.genai import types

# =========================================================
# [ì„¤ì •] API í‚¤ì™€ íŒŒì¼ëª…
# =========================================================
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "AIzaSyA0ADjqddqoa6ipqXNFaO5i4c2_-ByY5l4") 
INPUT_FILE_NAME = "KR_fantasy_alice.txt" 

LLM_MODEL_NAME = "gemini-2.5-flash"
OUTPUT_DIR = "output_v2" 
SCENE_DIR = os.path.join(OUTPUT_DIR, "scenes")

def create_output_dirs():
    if not os.path.exists(SCENE_DIR):
        os.makedirs(SCENE_DIR)

# =========================================================
# [PART 1] í•˜ì´ë¸Œë¦¬ë“œ ì²­ì»¤ (ìœ ì§€)
# =========================================================
class HybridSceneChunker:
    LOCATION_KEYWORDS = ['ë°©', 'ì§‘', 'ê±°ë¦¬', 'ìˆ²', 'êµ´', 'ì •ì›', 'í™€', 'ë°”ë‹¤', 'ì§‘ì•ˆ', 'ë‚˜ë¬´', 'ì„±', 'ë§ˆì„', 'êµì‹¤', 'ë³µë„', 'ì°½ê°€', 'ë˜ì „', 'ì™•ê¶', 'ë²•ì •']
    TIME_TRANSITIONS = ['ê·¸ë•Œ', 'ë‹¤ìŒë‚ ', 'ì ì‹œ í›„', 'ì•„ì¹¨', 'ì €ë…', 'ë°¤', 'ê°‘ìê¸°', 'ë©°ì¹  ë’¤', 'ëª‡ ì‹œê°„ í›„', 'ìƒˆë²½', 'ì˜¤í›„', 'ê³„ì ˆì´', 'ì‹œê°„ì´', 'ì–´ëŠë§']
    CHAPTER_PATTERNS = [r"^\s*ì œ\s*[0-9]+\s*[ì¥í™”í¸]", r"^\s*Chapter\s*[0-9]+", r"^\s*\*\*\*"]

    def __init__(self, target_chars=3500, min_chars=1000, threshold=5, overlap_chars=200):
        self.target_chars = target_chars
        self.min_chars = min_chars
        self.threshold = threshold
        self.overlap_chars = overlap_chars 

    def _calculate_score(self, text_segment):
        score = 0
        if any(k in text_segment for k in self.LOCATION_KEYWORDS): score += 5
        if any(k in text_segment for k in self.TIME_TRANSITIONS): score += 4
        return score

    def split_content(self, text: str) -> List[str]:
        text = text.replace('\r\n', '\n')
        paragraphs = re.split(r'\n\s*\n', text)
        final_scenes, current_scene, current_len = [], [], 0
        
        for para in paragraphs:
            para = para.strip()
            if not para: continue
            
            is_chapter = any(re.match(p, para, re.IGNORECASE) for p in self.CHAPTER_PATTERNS)
            score = self._calculate_score(para[:50])

            if (is_chapter and current_len > 0) or \
               (score >= self.threshold and current_len >= self.min_chars) or \
               (current_len + len(para) > self.target_chars):
                
                full_scene_text = "\n\n".join(current_scene)
                final_scenes.append(full_scene_text)
                
                current_scene = [full_scene_text[-self.overlap_chars:]] if len(full_scene_text) > self.overlap_chars else []
                current_scene.append(para)
                current_len = len(para)
            else:
                current_scene.append(para)
                current_len += len(para)

        if current_scene: final_scenes.append("\n\n".join(current_scene))
        return final_scenes

# =========================================================
# [PART 2] ìŠ¤í† ë¦¬ë³´ë“œ ì¶”ì¶œê¸° (ID ê°•ì œ ê³ ì • ë¡œì§ ì¶”ê°€)
# =========================================================
class StoryAnalyzer:
    def __init__(self, api_key):
        self.client = genai.Client(api_key=api_key)

    def analyze(self, chunk: Dict) -> Dict:
        prompt = f"""
        ë‹¹ì‹ ì€ ì†Œì„¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
        
        [í•„ìˆ˜ ì§€ì¹¨]
        1. 'Character'ì—ëŠ” ì‘ê°€, ì±… ì œëª©ì„ ì ˆëŒ€ ë„£ì§€ ë§ˆì„¸ìš”.
        2. 'summary'ëŠ” ìœ¡í•˜ì›ì¹™ì— ë”°ë¼ ëª…í™•í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”.
        3. 'atmosphere'ëŠ” ë¶„ìœ„ê¸°ë¥¼ ë‹¨ì–´ í˜•íƒœë¡œ(ì˜ˆ: ê¸´ë°•í•œ, í‰í™”ë¡œìš´) ì¶”ì¶œí•˜ì„¸ìš”.

        [TEXT]
        {chunk['text'][:4500]}
        
        [OUTPUT JSON FORMAT]
        {{
          "book_info": {{ "title": "ì†Œì„¤ ì œëª©", "author": "ì‘ê°€ ì´ë¦„" }},
          "scene_title": "ì†Œì œëª©",
          "summary": "ìš”ì•½ë¬¸",
          "atmosphere": "ë¶„ìœ„ê¸°",
          "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"],
          "entities": [
            {{ "name": "ì´ë¦„", "type": "Character/Place/Item", "desc": "íŠ¹ì§•", "action": "í–‰ë™" }}
          ]
        }}
        """
        try:
            response = self.client.models.generate_content(
                model=LLM_MODEL_NAME,
                contents=prompt,
                config=types.GenerateContentConfig(response_mime_type="application/json")
            )
            result = json.loads(response.text)
            if isinstance(result, list): result = result[0]
            
            # [ì¤‘ìš”] AIê°€ ë±‰ì€ IDë¥¼ ë¬´ì‹œí•˜ê³ , ì‹œìŠ¤í…œì´ ê´€ë¦¬í•˜ëŠ” ì§„ì§œ IDë¥¼ ê°•ì œ ì£¼ì…
            result['scene_id'] = chunk['id'] 
            
            if 'atmosphere' not in result: result['atmosphere'] = "N/A"
            if 'keywords' not in result: result['keywords'] = []
            return result
        except Exception as e:
            print(f"âš ï¸ ë¶„ì„ ì‹¤íŒ¨ ({chunk['id']}): {e}")
            # ì‹¤íŒ¨í•´ë„ IDëŠ” ë‚¨ê²¨ì•¼ ìˆœì„œê°€ ì•ˆ ë°€ë¦¼
            return {"scene_id": chunk['id'], "error": str(e)}

# =========================================================
# [PART 3] ë°”ì´ë¸” ìƒì„±ê¸° (ì •ë ¬ ë¡œì§ ê°•í™”)
# =========================================================
class WikiGenerator:
    @staticmethod
    def save_report_to_file(storyboard_list: List[Dict]):
        file_path = os.path.join(OUTPUT_DIR, "writer_bible_sorted.md")
        if not storyboard_list: return

        # 1. ì „ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ scene_id ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ (001 -> 002 -> ...)
        storyboard_list.sort(key=lambda x: x.get('scene_id', ''))

        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        valid_scenes = [s for s in storyboard_list if 'book_info' in s]
        if not valid_scenes: return
        
        first_valid = valid_scenes[0]
        book_title = first_valid.get('book_info', {}).get('title', 'Unknown Title')
        author = first_valid.get('book_info', {}).get('author', 'Unknown Author')
        
        # ë°ì´í„° ì§‘ê³„
        wiki = defaultdict(lambda: defaultdict(list))
        
        for scene in storyboard_list:
            s_id = scene.get('scene_id', 'unknown')
            if 'error' in scene: continue # ì—ëŸ¬ ë‚œ ì”¬ì€ íŒ¨ìŠ¤

            for ent in scene.get('entities', []):
                if ent['name'] in [book_title, author, "Project", "Book", "Unknown"]: continue
                # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                wiki[ent['type']][ent['name']].append({
                    "scene": s_id, 
                    "desc": ent['desc'], 
                    "action": ent['action']
                })

        with open(file_path, "w", encoding="utf-8") as f:
            f.write(f"# ğŸ“˜ {book_title} - ê³µì‹ ì„¤ì •ì§‘\n")
            f.write(f"**Sorted & Organized by StoryProof AI**\n\n")
            
            # ëª©ì°¨
            f.write("## ğŸ“‘ ëª©ì°¨\n")
            f.write("1. [ìŠ¤í† ë¦¬ë¼ì¸ (Timeline)](#1-ìŠ¤í† ë¦¬ë¼ì¸-timeline)\n")
            f.write("2. [ë“±ì¥ì¸ë¬¼ ìƒì„¸ (Characters)](#2-ë“±ì¥ì¸ë¬¼-ìƒì„¸-characters)\n")
            f.write("3. [ì•„ì´í…œ & ì¥ì†Œ (Items & Places)](#3-ì•„ì´í…œ--ì¥ì†Œ-items--places)\n\n---\n\n")
            
            # 1. ìŠ¤í† ë¦¬ë¼ì¸ (ì´ë¯¸ ì •ë ¬ë¨)
            f.write(f"## 1. ìŠ¤í† ë¦¬ë¼ì¸ (Timeline)\n")
            for scene in storyboard_list:
                if 'error' in scene: continue
                f.write(f"### ğŸ¬ **[{scene.get('scene_id')}] {scene.get('scene_title','')}**\n")
                f.write(f"> {scene.get('summary','')}\n\n")
            f.write("---\n\n")

            # 2. ë“±ì¥ì¸ë¬¼ (ìºë¦­í„°ë³„ -> ì”¬ ìˆœì„œëŒ€ë¡œ ì •ë ¬)
            f.write(f"## 2. ë“±ì¥ì¸ë¬¼ ìƒì„¸ (Characters)\n")
            char_items = wiki.get("Character", {})
            
            if not char_items:
                f.write("_ë°ì´í„° ì—†ìŒ_\n")
            else:
                # ìºë¦­í„° ì´ë¦„ ê°€ë‚˜ë‹¤ìˆœ ì •ë ¬? or ë“±ì¥ ë¹ˆë„ìˆœ? (ì—¬ê¸°ì„  ê°€ë‚˜ë‹¤ìˆœ)
                sorted_chars = sorted(char_items.items())
                
                for name, details in sorted_chars:
                    f.write(f"### ğŸ‘¤ {name}\n")
                    
                    # [í•µì‹¬] ì´ ìºë¦­í„°ì˜ ê¸°ë¡ì„ 'scene_id' ìˆœì„œëŒ€ë¡œ ì •ë ¬!
                    details.sort(key=lambda x: x['scene'])
                    
                    for d in details:
                        f.write(f"- `{d['scene']}`\n")
                        f.write(f"  - **íŠ¹ì§•:** {d['desc']}\n")
                        f.write(f"  - **í–‰ë™:** {d['action']}\n")
                    f.write("\n")
            f.write("---\n\n")

            # 3. ì•„ì´í…œ & ì¥ì†Œ
            f.write(f"## 3. ì•„ì´í…œ & ì¥ì†Œ (Items & Places)\n")
            for key in ["Item", "Place"]:
                items = wiki.get(key, {})
                if not items: continue
                f.write(f"### ğŸ”¹ {key}\n")
                sorted_items = sorted(items.items())
                
                for name, details in sorted_items:
                    # ì•„ì´í…œì€ ë‹¨ìˆœí™”í•´ì„œ ë³´ì—¬ì¤Œ (ê°€ì¥ ê¸´ ì„¤ëª… í•˜ë‚˜ + ë“±ì¥ íšŸìˆ˜)
                    details.sort(key=lambda x: x['scene'])
                    first_desc = details[0]['desc']
                    scene_list = ", ".join([d['scene'].replace('scene_', '') for d in details])
                    
                    f.write(f"- **{name}** (ë“±ì¥: {len(details)}íšŒ)\n")
                    f.write(f"  - ì„¤ëª…: {first_desc}\n")
                    f.write(f"  - ë“±ì¥: [{scene_list}]\n\n")

        print(f"âœ… ì •ë ¬ëœ ë°”ì´ë¸” ìƒì„± ì™„ë£Œ: {file_path}")

# =========================================================
# [ë©”ì¸ ì‹¤í–‰]
# =========================================================
def main():
    create_output_dirs()
    if not os.path.exists(INPUT_FILE_NAME):
        print(f"âŒ {INPUT_FILE_NAME} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."); return

    print(f"ğŸ“– ì†Œì„¤ íŒŒì¼ì„ ì½ëŠ” ì¤‘: {INPUT_FILE_NAME}")
    try:
        with open(INPUT_FILE_NAME, 'r', encoding='utf-8') as f: text = f.read()
    except:
        with open(INPUT_FILE_NAME, 'r', encoding='cp949') as f: text = f.read()

    print("âœ‚ï¸  í•˜ì´ë¸Œë¦¬ë“œ ì²­í‚¹ ì§„í–‰ ì¤‘...")
    chunks = HybridSceneChunker().split_content(text)
    
    # 001ë¶€í„° ë²ˆí˜¸ ë§¤ê¹€
    scene_data = [{'id': f"scene_{i+1:03d}", 'text': txt} for i, txt in enumerate(chunks)]

    # í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ (í™•ì¸ìš©)
    for scene in scene_data:
        with open(os.path.join(SCENE_DIR, f"{scene['id']}.txt"), "w", encoding="utf-8") as f:
            f.write(scene['text'])

    analyzer = StoryAnalyzer(GOOGLE_API_KEY)
    results = []
    print(f"ğŸš€ ë¶„ì„ ì‹œì‘ (ì´ {len(scene_data)}ê°œ ì”¬)")

    for i, chunk in enumerate(scene_data):
        print(f"  â–¶ [{i+1}/{len(scene_data)}] {chunk['id']} ë¶„ì„ ì¤‘...")
        res = analyzer.analyze(chunk)
        if res: results.append(res)
        time.sleep(1.0)

    if results:
        # JSON ì €ì¥
        with open(os.path.join(OUTPUT_DIR, "storyboard_analysis_sorted.json"), "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        # ë§ˆí¬ë‹¤ìš´ ì €ì¥ (ì—¬ê¸°ì„œ ì •ë ¬ ì‹¤í–‰ë¨)
        WikiGenerator.save_report_to_file(results)
    else:
        print("âŒ ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()