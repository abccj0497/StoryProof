# 04_hybrid_search_langchain_style.py


# JSON ë¡œë”© â†’ Hybrid Search(semantic + BM25 + filtering + threshold)
# â€œLangChainì—ì„œ í•©ì³ì„œâ€ì˜ í•µì‹¬ì€ (ë²¡í„°ê²°ê³¼ + í‚¤ì›Œë“œê²°ê³¼) â†’ í•˜ë‚˜ì˜ ë­í‚¹ìœ¼ë¡œ í•©ì¹˜ê¸°ì¸ë°,
# ì§€ê¸ˆì€ ë„¤ JSONì´ ì´ë¯¸ embeddingì„ ê°–ê³  ìˆìœ¼ë‹ˆ FAISSë¥¼ êµ³ì´ ì €ì¥/ë¡œë“œí•˜ì§€ ì•Šê³ ,

# semantic: cosine(=dot) ê²€ìƒ‰
# keyword: BM25Okapi
# ê²°í•©: score normalize í›„ ê°€ì¤‘í•©
# threshold: vec/bm25 ê°ê° ì„ê³„ê°’
# parent-child: child hit ì‹œ parent ë³¸ë¬¸ë„ ê°™ì´ ê·¼ê±°ë¡œ ì¶œë ¥

#ê²€ìƒ‰/ìŠ¤ì½”ì–´ë§ì€ childë§Œ ëŒ€ìƒìœ¼ë¡œ ìˆ˜í–‰
#child ê²°ê³¼ë¥¼ parent_idë¡œ ê·¸ë£¹í•‘
#parentë¥¼ ì¤‘ë³µ ì œê±° + parent ë‹¨ìœ„ë¡œ ë­í‚¹
#ì¶œë ¥ì€ parent ë³¸ë¬¸(evidence) + ê·¸ parentë¥¼ ì„ íƒí•˜ê²Œ ë§Œë“  child ê·¼ê±° ì¡°ê°ë“¤(ìŠ¤ë‹ˆí«/ì ìˆ˜)

# 04_hybrid_search_parent_lift.py
import json, os, re
import numpy as np
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer

MODEL_NAME = "Alibaba-NLP/gte-multilingual-base"

# === Hybrid ì„¤ì •(ì¶”í›„ íŠœë‹) ===
W_VEC = 0.6
W_BM25 = 0.4

VEC_THRESHOLD = 0.20   # cosine (normalize_embeddings=Trueë©´ dot==cos)
BM25_THRESHOLD = 1.0   # raw bm25 (ì½”í¼ìŠ¤/í† í¬ë‚˜ì´ì§•ì— ë”°ë¼ íŠœë‹)

TOPK_VEC = 30
TOPK_BM25 = 30
TOPK_CHILD = 30     # child í›„ë³´ í’€ í¬ê¸°
TOPK_PARENT = 8     # ìµœì¢… parent ì¶œë ¥ ê°œìˆ˜

# parent ì¶œë ¥ ì‹œ, parent í•˜ë‚˜ë‹¹ ë³´ì—¬ì¤„ child ê·¼ê±° ê°œìˆ˜
EVIDENCE_CHILD_PER_PARENT = 3

QUESTIONS = [
    "ì•¨ë¦¬ìŠ¤ëŠ” ì²˜ìŒì— ì–´ë””ì— ì•‰ì•„ ìˆì—ˆë‚˜ìš”?",
    "ì•¨ë¦¬ìŠ¤ê°€ ë³´ê¸°ì— ì–¸ë‹ˆê°€ ì½ë˜ ì±…ì—ëŠ” ë¬´ì—‡ì´ ì—†ì—ˆë‚˜ìš”?",
    "ì´ ë™í™”ì˜ ê¸€ì“´ì´ëŠ” ëˆ„êµ¬ì¸ê°€ìš”?",
    "ì´ ë™í™”ì˜ ì‚½í™”(ê·¸ë¦¼) ì‘ê°€ëŠ” ëˆ„êµ¬ì¸ê°€ìš”?",
    "ì•¨ë¦¬ìŠ¤ëŠ” ì§€ë£¨í•´ì§€ê¸° ì‹œì‘í–ˆì„ ë•Œ ë¬´ìŠ¨ ìƒê°ì„ í–ˆë‚˜ìš”?",
    "ì•¨ë¦¬ìŠ¤ê°€ í† ë¼ êµ´ë¡œ ë”°ë¼ë“¤ì–´ê°„ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€?",
    "í•˜ì–€ ì§ìŠ¹(í† ë¼)ì´ ë“¤ê³  ë‹¤ë‹ˆë˜ ë¬¼ê±´ì€?",
    "ì• ë²Œë ˆëŠ” ì•¨ë¦¬ìŠ¤ì—ê²Œ ì–´ë–¤ ì¡°ì–¸ì„ í–ˆëŠ”ê°€?",
    "ì²´ì…” ê³ ì–‘ì´ì˜ íŠ¹ì§•ì€?",
    "ì¬íŒì¥ì—ì„œ ì•¨ë¦¬ìŠ¤ëŠ” ì™•ì—ê²Œ ë­ë¼ê³  ì†Œë¦¬ì³¤ëŠ”ê°€?"
]


# ------------------------
# Utilities
# ------------------------
def normalize_scores(xs):
    if not xs:
        return xs
    mn, mx = min(xs), max(xs)
    if abs(mx - mn) < 1e-9:
        return [0.0 for _ in xs]
    return [(x - mn) / (mx - mn) for x in xs]


def pass_filter(meta, filt: dict):
    # filt ì˜ˆ: {"characters":"í°í† ë¼"} or {"strategy":"entity_child"}
    for k, v in filt.items():
        if k not in meta:
            return False
        cur = meta[k]
        if isinstance(cur, list):
            if v not in cur:
                return False
        else:
            if str(cur) != v:
                return False
    return True


def build_parent_lookup(data):
    return {d["id"]: d for d in data if d.get("type") == "parent"}


def build_child_pool(data, filt=None):
    # âœ… ê²€ìƒ‰ì€ childë¡œë§Œ!
    children = [d for d in data if d.get("type") == "child"]

    if filt:
        children = [d for d in children if pass_filter(d.get("metadata", {}), filt)]

    # parent_id ì—†ëŠ” childëŠ” parent liftê°€ ì•ˆë˜ë¯€ë¡œ ì œì™¸(ì›í•˜ë©´ keepí•´ë„ ë¨)
    children = [d for d in children if d.get("parent_id")]
    return children


def snippet(text: str, n: int = 220) -> str:
    t = text.replace("\n", " ").strip()
    return (t[:n] + "...") if len(t) > n else t


# ------------------------
# Child-level Hybrid Search
# ------------------------
def hybrid_search_children(children, query, model):
    """
    children: List[dict] (type=child)
    return: List[dict] child results (with vec/bm25/hybrid scores)
    """
    if not children:
        return []

    q_emb = model.encode([query], normalize_embeddings=True)[0].astype(np.float32)
    doc_embs = np.array([d["embedding"] for d in children], dtype=np.float32)

    # vec score (dot == cosine)
    vec_scores = (doc_embs @ q_emb).tolist()

    # bm25 score
    tokenized = [d["content"].split() for d in children]
    bm25 = BM25Okapi(tokenized)
    bm25_scores = bm25.get_scores(query.split()).tolist()

    # threshold: (vec>=t) OR (bm25>=t)
    keep = []
    for i, (sv, sb) in enumerate(zip(vec_scores, bm25_scores)):
        if (sv >= VEC_THRESHOLD) or (sb >= BM25_THRESHOLD):
            keep.append(i)

    if not keep:
        return []

    cand = [children[i] for i in keep]
    vec2 = [vec_scores[i] for i in keep]
    bm2 = [bm25_scores[i] for i in keep]

    vec2n = normalize_scores(vec2)
    bm2n = normalize_scores(bm2)
    hybrid = [W_VEC * v + W_BM25 * b for v, b in zip(vec2n, bm2n)]

    # rank by hybrid (child-level)
    order = sorted(range(len(cand)), key=lambda i: hybrid[i], reverse=True)[:TOPK_CHILD]

    out = []
    for i in order:
        d = cand[i]
        out.append({
            "child_id": d["id"],
            "parent_id": d["parent_id"],
            "child_text": d["content"],
            "child_metadata": d.get("metadata", {}),
            "hybrid_score": float(hybrid[i]),
            "vec_score": float(vec2[i]),
            "bm25_score": float(bm2[i]),
        })
    return out


# ------------------------
# Parent lifting + dedup + rerank
# ------------------------
def lift_and_rank_parents(child_results, parent_lookup):
    """
    child_results: child ranked list
    parent_lookup: dict[parent_id -> parent_doc]

    return: ranked parent list, each with evidence children (dedup)
    """
    if not child_results:
        return []

    # group by parent_id
    grouped = {}
    for r in child_results:
        pid = r["parent_id"]
        if pid not in parent_lookup:
            continue
        grouped.setdefault(pid, []).append(r)

    if not grouped:
        return []

    parent_items = []
    for pid, childs in grouped.items():
        # child ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        childs_sorted = sorted(childs, key=lambda x: x["hybrid_score"], reverse=True)

        # âœ… parent score: ëŒ€í‘œê°’(ìµœëŒ€) + ë³´ì¡°(ìƒìœ„ ëª‡ ê°œ í•©) ì¤‘ ì„ íƒ
        # ë³´í†µ maxê°€ ì•ˆì •ì ì´ê³ , sumì€ childê°€ ì—¬ëŸ¬ê°œ ê±¸ë¦´ìˆ˜ë¡ ìœ ë¦¬í•´ì§€ëŠ” ê²½í–¥ì´ ìˆìŒ
        parent_score = max(c["hybrid_score"] for c in childs_sorted)

        # evidence child: ìƒìœ„ Nê°œ
        evidence = childs_sorted[:EVIDENCE_CHILD_PER_PARENT]

        pdoc = parent_lookup[pid]
        parent_items.append({
            "parent_id": pid,
            "parent_score": float(parent_score),
            "parent_metadata": pdoc.get("metadata", {}),
            "parent_text": pdoc.get("content", ""),
            "evidence_children": evidence,
        })

    # âœ… parent ë‹¨ìœ„ë¡œ ë­í‚¹(ì¤‘ë³µ ì œê±° ì™„ë£Œ)
    parent_items = sorted(parent_items, key=lambda x: x["parent_score"], reverse=True)
    return parent_items[:TOPK_PARENT]


def guess_answer(query: str, parent_text: str, evidence_children) -> str:
    """
    LLM ì—†ì´ ë°œì·Œ ê¸°ë°˜ìœ¼ë¡œ 'ë‹µ' ì¶”ì •:
    - ê¸°ë³¸: ê°€ì¥ ê´€ë ¨ child ìŠ¤ë‹ˆí« 1ê°œë¥¼ ë‹µì²˜ëŸ¼ ë³´ì—¬ì¤Œ
    - ì €ì/ì‚½í™” ë“±ì€ parentì—ì„œ í‚¤ì›Œë“œ ë¼ì¸ ìš°ì„ 
    """
    if any(k in query for k in ["ëˆ„êµ¬", "ì‘ê°€", "ê¸€ì“´ì´", "ì €ì", "ì‚½í™”", "ê·¸ë¦¼"]):
        lines = re.split(r"\n+", parent_text)
        for ln in lines:
            if any(k in ln for k in ["ê¸€", "ì§€ì€ì´", "ì˜®ê¹€", "ì‚½í™”", "ê·¸ë¦¼", "ì €ì"]):
                if len(ln.strip()) > 2:
                    return ln.strip()[:220]

    if evidence_children:
        return snippet(evidence_children[0]["child_text"], 220)

    return snippet(parent_text, 220)


# ------------------------
# Main runner
# ------------------------
def run(json_file: str, export_file: str = "04_parent_lift_result.txt", filter_kv: str = ""):
    print(f">>> [04ë²ˆ Parent-Child ì •ì„ Hybrid] JSON ë¡œë”©: {json_file}")
    if not os.path.exists(json_file):
        print("âŒ JSON íŒŒì¼ ì—†ìŒ")
        return

    with open(json_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    print(">>> ëª¨ë¸ ë¡œë”© ì¤‘...")
    model = SentenceTransformer(MODEL_NAME, trust_remote_code=True)

    # filter íŒŒì‹±: "characters=í°í† ë¼,strategy=entity_child"
    filt = None
    if filter_kv.strip():
        filt = {}
        for kv in filter_kv.split(","):
            k, v = kv.split("=", 1)
            filt[k.strip()] = v.strip()

    # âœ… parent lookup + child pool êµ¬ì„±
    parent_lookup = build_parent_lookup(data)
    children = build_child_pool(data, filt=filt)

    if not parent_lookup:
        print("âŒ parent ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (PC ì¸ë±ìŠ¤ì¸ì§€ í™•ì¸: type='parent')")
        return
    if not children:
        print("âŒ child ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (PC ì¸ë±ìŠ¤ì¸ì§€ í™•ì¸: type='child')")
        return

    with open(export_file, "w", encoding="utf-8") as out:
        def log(s):
            print(s)
            out.write(s + "\n")

        log("=" * 100)
        log("ğŸš€ [Parentâ€“Child RAG ì •ì„ Hybrid Search ë¦¬í¬íŠ¸]")
        log(f"   - model: {MODEL_NAME}")
        log(f"   - json : {json_file}")
        log(f"   - ê²€ìƒ‰ëŒ€ìƒ: child ONLY â†’ ì¶œë ¥ì€ parent ONLY (dedup)")
        log(f"   - weights: vec={W_VEC}, bm25={W_BM25}")
        log(f"   - threshold: vec>={VEC_THRESHOLD}, bm25>={BM25_THRESHOLD}")
        log(f"   - filter: {filt}")
        log("=" * 100 + "\n")

        for qi, q in enumerate(QUESTIONS, 1):
            log(f"â“ [Q{qi}] {q}")

            # 1) child ê²€ìƒ‰
            child_results = hybrid_search_children(children, q, model)
            if not child_results:
                log("   âŒ child ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ (threshold/filterë¡œ ì œê±°ë¨)")
                log("-" * 80)
                continue

            # 2) parent lift + dedup + parent rerank
            parent_results = lift_and_rank_parents(child_results, parent_lookup)
            if not parent_results:
                log("   âŒ parent lift ì‹¤íŒ¨ (parent_id ë§¤ì¹­ ì•ˆë¨)")
                log("-" * 80)
                continue

            # 3) ì¶œë ¥: ë‹µ(ë°œì·Œ ê¸°ë°˜) + parent ê·¼ê±° + child ê·¼ê±°ë“¤
            top_parent = parent_results[0]
            ans = guess_answer(q, top_parent["parent_text"], top_parent["evidence_children"])

            log(f"âœ… ì¶”ì • ë‹µ(ë°œì·Œ ê¸°ë°˜): {ans}")
            log(f"ğŸ“Œ Top-1 Parent Score: {top_parent['parent_score']:.4f}")

            # parent ê·¼ê±°(ë°œì·Œ)
            p_ev = snippet(top_parent["parent_text"], 420)
            log(f"ğŸ§© Parent ê·¼ê±°(ë°œì·Œ): {p_ev}")

            # child ê·¼ê±°(ì™œ ì´ parentì¸ê°€)
            log("ğŸ” ì„ íƒ ê·¼ê±°(Child evidence):")
            for r in top_parent["evidence_children"]:
                log(
                    f"   - child(h={r['hybrid_score']:.4f}, vec={r['vec_score']:.4f}, bm25={r['bm25_score']:.2f}) | "
                    f"{snippet(r['child_text'], 220)}"
                )

            # ì¶”ê°€ parent ëª‡ ê°œ í‘œì‹œ
            log("\nğŸ“š ì¶”ê°€ Parent í›„ë³´(ì¤‘ë³µ ì œê±° ì™„ë£Œ):")
            for rank, pr in enumerate(parent_results[:3], 1):
                log(f"   ğŸ¥‡ Parent Top {rank} | score={pr['parent_score']:.4f} | id={pr['parent_id']}")
                log(f"      parent ë°œì·Œ: {snippet(pr['parent_text'], 220)}")

            log("-" * 80)

    print(f"\nâœ… ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {export_file}")


if __name__ == "__main__":
    # ì˜ˆ:
    # run("01_entity_pc_data.json", filter_kv="characters=í°í† ë¼")
    run("01_entity_pc_data.json")
