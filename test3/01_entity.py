# 01_gen_entity_pc.py

#parent = ë¬¸ë‹¨(para)
#child = parent ë‚´ë¶€ë¥¼ Recursive(ì‘ê²Œ) ìª¼ê°  ê²ƒ(ê¸°ë³¸ 350/70)
#ì €ì¥ JSONì— type: parent|child, parent_id í¬í•¨

import json, uuid, re, os, time
import fitz
from sentence_transformers import SentenceTransformer
from langchain_text_splitters import RecursiveCharacterTextSplitter

SOURCE_FILE = "alice_utf8.txt"
OUTPUT_FILE = "01_entity_pc_data.json"
MODEL_NAME = "Alibaba-NLP/gte-multilingual-base"

def clean_text(text):
    text = re.sub(r"http\S+", "", text)
    text = re.sub(r"ê·¸ë¦¼ì„¤ëª…\s*:.*", "", text)
    text = re.sub(r"[-=]{3,}", "", text)
    text = re.sub(r"\n{3,}", "\n\n", text)
    return text.strip()

def load_any(path: str) -> str:
    if path.lower().endswith(".txt"):
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    if path.lower().endswith(".pdf"):
        doc = fitz.open(path)
        pages = [doc.load_page(i).get_text("text") for i in range(len(doc))]
        return "\n".join(pages)
    raise ValueError("ì§€ì› í™•ì¥ì: .txt, .pdf")

def get_tags(text):
    meta = {"characters": [], "items": []}
    if any(x in text for x in ["ì•¨ë¦¬ìŠ¤", "ì†Œë…€"]):
        meta["characters"].append("ì•¨ë¦¬ìŠ¤")
    if any(x in text for x in ["í† ë¼", "í° í† ë¼", "í•˜ì–€ í† ë¼"]):
        meta["characters"].append("í°í† ë¼")
    if any(x in text for x in ["ì²´ì…”", "ì²´ì…” ê³ ì–‘ì´"]):
        meta["characters"].append("ì²´ì…”ê³ ì–‘ì´")
    if "ì• ë²Œë ˆ" in text:
        meta["characters"].append("ì• ë²Œë ˆ")
    if "ì™•" in text:
        meta["characters"].append("ì™•")
    if "ì—¬ì™•" in text:
        meta["characters"].append("ì—¬ì™•")

    for item in ["ì‹œê³„", "ì—´ì‡ ", "ì¥ê°‘", "ë¶€ì±„", "ë²„ì„¯", "ë³‘", "ì¼€ì´í¬"]:
        if item in text:
            meta["items"].append(item)

    # ì¤‘ë³µ ì œê±°
    meta["characters"] = list(dict.fromkeys(meta["characters"]))
    meta["items"] = list(dict.fromkeys(meta["items"]))
    return meta

def run(source_file: str = SOURCE_FILE, output_file: str = OUTPUT_FILE):
    print(f">>> [01ë²ˆ ì „ëµ: Entity + Parent-Child] {source_file} ì²˜ë¦¬ ì‹œì‘...")
    if not os.path.exists(source_file):
        print("âŒ íŒŒì¼ ì—†ìŒ")
        return

    raw = load_any(source_file)
    text = clean_text(raw)

    # parent: ë¬¸ë‹¨
    parents = [c.strip() for c in text.split("\n\n") if len(c.strip()) > 80]

    # child: parent ë‚´ë¶€ë¥¼ recursiveë¡œ ë” ì‘ê²Œ ë¶„í• 
    child_splitter = RecursiveCharacterTextSplitter(chunk_size=350, chunk_overlap=70)

    print("   ...ëª¨ë¸ ë¡œë”© ì¤‘...")
    model = SentenceTransformer(MODEL_NAME, trust_remote_code=True)

    data = []
    start_time = time.time()

    # parent ì„ë² ë”©
    print(f"   ...Parent ì„ë² ë”© ë³€í™˜ ì‹œì‘ (ì´ {len(parents)}ê°œ ë¬¸ë‹¨)")
    parent_embeddings = model.encode(parents, show_progress_bar=True)

    parent_ids = []
    for i, p in enumerate(parents):
        pid = str(uuid.uuid4())
        parent_ids.append(pid)
        data.append({
            "id": pid,
            "type": "parent",
            "parent_id": None,
            "content": p,
            "metadata": {"strategy": "entity_parent", **get_tags(p)},
            "embedding": parent_embeddings[i].tolist()
        })

    # child ì„ë² ë”©
    all_children = []
    child_parent_link = []
    for pid, p in zip(parent_ids, parents):
        docs = child_splitter.create_documents([p])
        chunks = [d.page_content.strip() for d in docs if len(d.page_content.strip()) > 40]
        for c in chunks:
            all_children.append(c)
            child_parent_link.append(pid)

    print(f"   ...Child ì„ë² ë”© ë³€í™˜ ì‹œì‘ (ì´ {len(all_children)}ê°œ)")
    child_embeddings = model.encode(all_children, show_progress_bar=True)

    for i, c in enumerate(all_children):
        data.append({
            "id": str(uuid.uuid4()),
            "type": "child",
            "parent_id": child_parent_link[i],
            "content": c,
            "metadata": {"strategy": "entity_child", **get_tags(c)},
            "embedding": child_embeddings[i].tolist()
        })

    duration = time.time() - start_time

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

    # ê²°ê³¼ ë¦¬í¬íŠ¸
    parent_cnt = sum(1 for d in data if d["type"] == "parent")
    child_cnt = sum(1 for d in data if d["type"] == "child")
    vec_ok = all("embedding" in d and len(d["embedding"]) > 0 for d in data)

    print("\n" + "=" * 48)
    print("ğŸ“Š [01ë²ˆ Entity+PC ê²°ê³¼ ë¦¬í¬íŠ¸]")
    print(f"âœ… ì €ì¥ ì™„ë£Œ          : {output_file}")
    print(f"â±ï¸ ì†Œìš” ì‹œê°„          : {duration:.2f} ì´ˆ")
    print(f"ğŸ“¦ Parent ì²­í¬ ê°œìˆ˜   : {parent_cnt} ê°œ")
    print(f"ğŸ“¦ Child ì²­í¬ ê°œìˆ˜    : {child_cnt} ê°œ")
    print(f"ğŸ”¢ ë²¡í„°í™” ì •ìƒ ì—¬ë¶€   : {'OK' if vec_ok else 'WARN'}")
    print("=" * 48)

if __name__ == "__main__":
    run()
