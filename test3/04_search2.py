# 04_hybrid_search_parent_lift_top5.py  (A ë°©ì‹)
import json, os, re
from typing import Dict, List, Optional

import numpy as np
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer

MODEL_NAME = "Alibaba-NLP/gte-multilingual-base"

# âœ… ì—¬ê¸°ë§Œ ë°”ê¿”ê°€ë©° ì‹¤í–‰
INDEX_FILE = "03_sliding_pc_data.json" #"02_recursive_pc_data.json" #"01_entity_pc_data.json"  
EXPORT_FILE = "04_parent_lift_top5_result.txt"

# (ì„ íƒ) metadata filtering: ì˜ˆ) {"characters": "í°í† ë¼"}
FILTER = None  # ë˜ëŠ” {"characters": "í°í† ë¼"}

# Hybrid weights
W_VEC = 0.6
W_BM25 = 0.4

# Thresholds
VEC_THRESHOLD = 0.20
BM25_THRESHOLD = 1.0

TOPK_CHILD = 50
TOPK_PARENT = 5
EVIDENCE_CHILD_PER_PARENT = 3

QUESTIONS = [
    # "ì•¨ë¦¬ìŠ¤ëŠ” ì²˜ìŒì— ì–´ë””ì— ì•‰ì•„ ìˆì—ˆë‚˜ìš”?",
    # "ì•¨ë¦¬ìŠ¤ê°€ ë³´ê¸°ì— ì–¸ë‹ˆê°€ ì½ë˜ ì±…ì—ëŠ” ë¬´ì—‡ì´ ì—†ì—ˆë‚˜ìš”?",
    # "ì´ ë™í™”ì˜ ê¸€ì“´ì´ëŠ” ëˆ„êµ¬ì¸ê°€ìš”?",
    # "ì´ ë™í™”ì˜ ì‚½í™”(ê·¸ë¦¼) ì‘ê°€ëŠ” ëˆ„êµ¬ì¸ê°€ìš”?",
    # "ì•¨ë¦¬ìŠ¤ëŠ” ì§€ë£¨í•´ì§€ê¸° ì‹œì‘í–ˆì„ ë•Œ ë¬´ìŠ¨ ìƒê°ì„ í–ˆë‚˜ìš”?",
    # "ì•¨ë¦¬ìŠ¤ê°€ í† ë¼ êµ´ë¡œ ë”°ë¼ë“¤ì–´ê°„ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€?",
    # "í•˜ì–€ ì§ìŠ¹(í† ë¼)ì´ ë“¤ê³  ë‹¤ë‹ˆë˜ ë¬¼ê±´ì€?",
    # "ì• ë²Œë ˆëŠ” ì•¨ë¦¬ìŠ¤ì—ê²Œ ì–´ë–¤ ì¡°ì–¸ì„ í–ˆëŠ”ê°€?",
    # "ì²´ì…” ê³ ì–‘ì´ì˜ íŠ¹ì§•ì€?",
    # "ì¬íŒì¥ì—ì„œ ì•¨ë¦¬ìŠ¤ëŠ” ì™•ì—ê²Œ ë­ë¼ê³  ì†Œë¦¬ì³¤ëŠ”ê°€?",

#    "1. ì•¨ë¦¬ìŠ¤ê°€ ê°•ë‘‘ì—ì„œ ì§€ë£¨í•´í•œ ì´ìœ ëŠ” ë¬´ì—‡ì´ì—ˆë‚˜?",
#    "2. ì–¸ë‹ˆê°€ ì½ë˜ ì±…ì—ì„œ ì•¨ë¦¬ìŠ¤ê°€ ë§ˆìŒì— ë“¤ì§€ ì•Šì•˜ë˜ ì ì€ ë¬´ì—‡ì´ì—ˆë‚˜?",
#    "3. í° í† ë¼ê°€ ì–´ë–¤ í–‰ë™ì„ í•´ì„œ ì•¨ë¦¬ìŠ¤ê°€ ì´ìƒí•˜ë‹¤ê³  ëŠê¼ˆë‚˜?",
#    "4. ì•¨ë¦¬ìŠ¤ëŠ” í° í† ë¼ë¥¼ ë”°ë¼ ì–´ë””ë¡œ ë“¤ì–´ê°”ë‚˜?",
#    "5. ì•¨ë¦¬ìŠ¤ëŠ” í† ë¼êµ´ì— ë›°ì–´ë“¤ê¸° ì „ì— ì–´ë–¤ ìœ„í—˜ì„ ìƒê°í•˜ì§€ ëª»í–ˆë‚˜?",

#   "6. ë–¨ì–´ì§€ë˜ ì¤‘ ì•¨ë¦¬ìŠ¤ê°€ ì£¼ì›Œ ë“  í•­ì•„ë¦¬ì—ëŠ” ë¬´ì—‡ì´ ì í˜€ ìˆì—ˆë‚˜?",
#   "7. ê¸´ ë³µë„ì—ì„œ ì•¨ë¦¬ìŠ¤ê°€ ì²˜ìŒ ë°œê²¬í•œ ì—´ì‡ ëŠ” ì–´ë””ì— ìˆì—ˆë‚˜?",
#   "8. ì‘ì€ ë¬¸ ë„ˆë¨¸ì—ëŠ” ì–´ë–¤ ì¥ì†Œê°€ ë³´ì˜€ë‚˜?",
#   "9. â€˜ë‚  ë§ˆì…”â€™ ë³‘ì„ ë§ˆì‹œê¸° ì „ì— ì•¨ë¦¬ìŠ¤ëŠ” ì–´ë–¤ ì•ˆì „ í™•ì¸ì„ í–ˆë‚˜?",
#   "10. ë³‘ì„ ë§ˆì‹  ë’¤ ì•¨ë¦¬ìŠ¤ì˜ í‚¤ëŠ” ì–´ë–»ê²Œ ë³€í–ˆë‚˜?",

    "11. ì‘ì•„ì§„ ì•¨ë¦¬ìŠ¤ê°€ ì—´ì‡ ë¥¼ ì“°ì§€ ëª»í–ˆë˜ ì§ì ‘ì ì¸ ì´ìœ ëŠ” ë¬´ì—‡ì´ì—ˆë‚˜?",
    "12. â€˜ë‚  ë¨¹ì–´â€™ ì¼€ì´í¬ë¥¼ ë¨¹ì€ ë’¤ ì•¨ë¦¬ìŠ¤ì—ê²Œ ì–´ë–¤ ë³€í™”ê°€ ì¼ì–´ë‚¬ë‚˜?",
    "13. í° í† ë¼ëŠ” ì•¨ë¦¬ìŠ¤ë¥¼ ëˆ„êµ¬ë¡œ ì°©ê°í–ˆë‚˜?",
    "14. í° í† ë¼ì˜ ì°©ê° ë•Œë¬¸ì— ì•¨ë¦¬ìŠ¤ê°€ ë“¤ì–´ê°€ê²Œ ëœ ì¥ì†ŒëŠ” ì–´ë””ì˜€ë‚˜?",
    "15. í† ë¼ì˜ ì§‘ì—ì„œ ì•¨ë¦¬ìŠ¤ê°€ ì§‘ ì•ˆì— ë¼ê²Œ ëœ ì›ì¸ì€ ë¬´ì—‡ì´ì—ˆë‚˜?",
]

def normalize_scores(xs: List[float]) -> List[float]:
    if not xs:
        return xs
    mn, mx = min(xs), max(xs)
    if abs(mx - mn) < 1e-9:
        return [0.0 for _ in xs]
    return [(x - mn) / (mx - mn) for x in xs]

def pass_filter(meta: dict, filt: dict) -> bool:
    for k, v in filt.items():
        if k not in meta:
            return False
        cur = meta[k]
        if isinstance(cur, list):
            if v not in cur:
                return False
        else:
            if str(cur) != v:
                return False
    return True

def build_parent_lookup(data: list) -> Dict[str, dict]:
    return {d["id"]: d for d in data if d.get("type") == "parent"}

def build_child_pool(data: list, filt: Optional[dict]) -> list:
    children = [d for d in data if d.get("type") == "child" and d.get("parent_id")]
    if filt:
        children = [d for d in children if pass_filter(d.get("metadata", {}), filt)]
    return children

def snippet(text: str, n: int = 220) -> str:
    t = text.replace("\n", " ").strip()
    return (t[:n] + "...") if len(t) > n else t

def hybrid_search_children(children: list, query: str, model: SentenceTransformer) -> list:
    if not children:
        return []

    q_emb = model.encode([query], normalize_embeddings=True)[0].astype(np.float32)
    doc_embs = np.array([d["embedding"] for d in children], dtype=np.float32)

    vec_scores = (doc_embs @ q_emb).tolist()

    tokenized = [d["content"].split() for d in children]
    bm25 = BM25Okapi(tokenized)
    bm25_scores = bm25.get_scores(query.split()).tolist()

    keep = []
    for i, (sv, sb) in enumerate(zip(vec_scores, bm25_scores)):
        if (sv >= VEC_THRESHOLD) or (sb >= BM25_THRESHOLD):
            keep.append(i)
    if not keep:
        return []

    cand = [children[i] for i in keep]
    vec2 = [vec_scores[i] for i in keep]
    bm2 = [bm25_scores[i] for i in keep]

    vec2n = normalize_scores(vec2)
    bm2n = normalize_scores(bm2)
    hybrid = [W_VEC * v + W_BM25 * b for v, b in zip(vec2n, bm2n)]

    order = sorted(range(len(cand)), key=lambda i: hybrid[i], reverse=True)[:TOPK_CHILD]

    out = []
    for i in order:
        d = cand[i]
        out.append({
            "child_id": d["id"],
            "parent_id": d["parent_id"],
            "child_text": d["content"],
            "child_metadata": d.get("metadata", {}),
            "hybrid_score": float(hybrid[i]),
            "vec_score": float(vec2[i]),
            "bm25_score": float(bm2[i]),
        })
    return out

def lift_and_rank_parents(child_results: list, parent_lookup: dict) -> list:
    grouped = {}
    for r in child_results:
        pid = r["parent_id"]
        if pid not in parent_lookup:
            continue
        grouped.setdefault(pid, []).append(r)

    parent_items = []
    for pid, childs in grouped.items():
        childs_sorted = sorted(childs, key=lambda x: x["hybrid_score"], reverse=True)
        parent_score = max(c["hybrid_score"] for c in childs_sorted)
        evidence = childs_sorted[:EVIDENCE_CHILD_PER_PARENT]

        pdoc = parent_lookup[pid]
        parent_items.append({
            "parent_id": pid,
            "parent_score": float(parent_score),
            "parent_metadata": pdoc.get("metadata", {}),
            "parent_text": pdoc.get("content", ""),
            "evidence_children": evidence,
        })

    parent_items = sorted(parent_items, key=lambda x: x["parent_score"], reverse=True)
    return parent_items[:TOPK_PARENT]

def guess_answer(query: str, parent_text: str, evidence_children: list) -> str:
    if any(k in query for k in ["ëˆ„êµ¬", "ì‘ê°€", "ê¸€ì“´ì´", "ì €ì", "ì‚½í™”", "ê·¸ë¦¼"]):
        lines = re.split(r"\n+", parent_text)
        for ln in lines:
            if any(k in ln for k in ["ê¸€ì“´ì´", "ì§€ì€ì´", "ì˜®ê¹€", "ì‚½í™”", "ê·¸ë¦¼", "ì €ì", "ê·¸  ë¦¼"]):
                if len(ln.strip()) > 2:
                    return ln.strip()[:220]
    if evidence_children:
        return snippet(evidence_children[0]["child_text"], 220)
    return snippet(parent_text, 220)

def run():
    print(f">>> [04] Parentâ€“Child ì •ì„ Hybrid | index={INDEX_FILE}")
    if not os.path.exists(INDEX_FILE):
        print("âŒ JSON íŒŒì¼ ì—†ìŒ:", INDEX_FILE)
        return

    with open(INDEX_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)

    parent_lookup = build_parent_lookup(data)
    children = build_child_pool(data, filt=FILTER)

    if not parent_lookup:
        print("âŒ parent ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (type='parent' í™•ì¸)")
        return
    if not children:
        print("âŒ child ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (type='child' í™•ì¸)")
        return

    print(">>> ëª¨ë¸ ë¡œë”© ì¤‘...")
    model = SentenceTransformer(MODEL_NAME, trust_remote_code=True)

    with open(EXPORT_FILE, "w", encoding="utf-8") as out:
        def log(s: str):
            print(s)
            out.write(s + "\n")

        log("=" * 110)
        log("ğŸš€ [Parentâ€“Child ì •ì„ Hybrid Search ë¦¬í¬íŠ¸ | Top-5 Parents]")
        log(f"   - index     : {INDEX_FILE}")
        log(f"   - model     : {MODEL_NAME}")
        log(f"   - filter    : {FILTER}")
        log(f"   - weights   : vec={W_VEC}, bm25={W_BM25}")
        log(f"   - threshold : vec>={VEC_THRESHOLD}, bm25>={BM25_THRESHOLD}")
        log("=" * 110 + "\n")

        for qi, q in enumerate(QUESTIONS, 1):
            log(f"â“ [Q{qi}] {q}")

            child_results = hybrid_search_children(children, q, model)
            if not child_results:
                log("   âŒ child ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ (threshold/filterë¡œ ì œê±°ë¨)")
                log("-" * 90)
                continue

            parent_results = lift_and_rank_parents(child_results, parent_lookup)
            if not parent_results:
                log("   âŒ parent lift ì‹¤íŒ¨ (parent_id ë§¤ì¹­ ì•ˆë¨)")
                log("-" * 90)
                continue

            log(f"âœ… Top-{len(parent_results)} Parents (ìœ ì‚¬ë„ ìˆœ)")
            for rank, pr in enumerate(parent_results, 1):
                ans = guess_answer(q, pr["parent_text"], pr["evidence_children"])
                log(f"\n   ğŸ¥‡ Parent Rank {rank}")
                log(f"      - parent_score(hybrid): {pr['parent_score']:.4f}")
                log(f"      - ë‹µë³€ í›„ë³´(ë°œì·Œ): {ans}")
                log(f"      - Parent ê·¼ê±°(ë°œì·Œ): {snippet(pr['parent_text'], 420)}")
                log("      - ì„ íƒ ê·¼ê±°(Child evidence):")
                for r in pr["evidence_children"]:
                    log(
                        f"         â€¢ child(h={r['hybrid_score']:.4f}, vec={r['vec_score']:.4f}, bm25={r['bm25_score']:.2f}) "
                        f"| {snippet(r['child_text'], 220)}"
                    )

            log("\n" + "-" * 90)

    print(f"\nâœ… ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {EXPORT_FILE}")

if __name__ == "__main__":
    run()
